{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "worse-welding",
   "metadata": {
    "id": "worse-welding"
   },
   "source": [
    "# Task 2: Develop Recurrent Neural Network(s) For Sequence-to-Sequence Classification\n",
    "\n",
    "**Note**: I have run the code on a local machine GPU due to limited resources provided by the Google Colab platform. Therefore, you might get different results than mine even though the reproducibility measures applied below. That's just how GPUs work...\n",
    "\n",
    "To begin with, we provide a walkthrough on how to replicate the task on Google Colab. First, we need to extract the soybean dataset from the ZIP file (download from MyAberdeen). Therefore, we first mount our drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "W1b50T6RwUp1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "error",
     "timestamp": 1635958507876,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "W1b50T6RwUp1",
    "outputId": "e3e82998-c749-4944-c809-e1cf6b9bfcec"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lUM3PgdkEYNq",
   "metadata": {
    "id": "lUM3PgdkEYNq"
   },
   "source": [
    "\n",
    "Then, we upload the dataset ZIP file to our google drive and execute:\n",
    "\n",
    "    !unzip your_drive_path_to_data.zip -d './data/' \n",
    "\n",
    "where *your_drive_path_to_data.zip* (*CS5062_AssessmentII_Dataset.zip* in our case) should be replaced by the actual path of the dataset ZIP file on your drive.\n",
    "\n",
    "Alternatively, we can place the dataset zip file in the current directory and execute (tested in colab):\n",
    "\n",
    "    !unzip 'CS5062_AssessmentII_Dataset.zip' -d './data/' \n",
    "\n",
    "Below is the location of the dataset ZIP file on my Google Drive. This will differ in your case, so please adjust as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ANVyR_zbChB_",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 113,
     "status": "ok",
     "timestamp": 1635958498872,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "ANVyR_zbChB_",
    "outputId": "b0823b9f-c962-49e5-fc80-8d357b1f4433"
   },
   "outputs": [],
   "source": [
    "!unzip -q '/content/drive/MyDrive/Colab Notebooks/Assessment_2/CS5062_AssessmentII_Dataset.zip' -d './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6-1htWLbt2y5",
   "metadata": {
    "id": "6-1htWLbt2y5"
   },
   "source": [
    "\n",
    "### Setting a Fixed Seed Value for the Random Number Generator and Importing Libraries\n",
    "\n",
    "Randomness is in the nature of neural networks which employ it to ensure a better performance on a specific task. However, we need to seed the random number generator to get reproducible results when training and comparing models. \n",
    "\n",
    "*Note that randomness might still occur such as the random initialisation of model weights when constructing a model. Thus, the output results might differ each time the script is run (generally on GPU). We put great deal of effort into making the script results as repeatable as possible.*\n",
    "\n",
    "- First, we install the new Tensorflow determinism package allowing reproducibility on GPUs.\n",
    "\n",
    "\n",
    "- Then, we seed the random number generators and import the required packages for model development and visualisation (i.e tensorflow, keras, matplotlib)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w2RNnMLKVPgq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5091,
     "status": "ok",
     "timestamp": 1635957099626,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "w2RNnMLKVPgq",
    "outputId": "04d10e53-aa04-4065-b833-91bc047eead2"
   },
   "outputs": [],
   "source": [
    "# Install the determinism package of Tensorflow\n",
    "# If the program throws attribute error the simply\n",
    "# uninstall the Keras package (since tensorflow already\n",
    "# provides it)\n",
    "!pip install tensorflow-determinism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "comparable-minutes",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "error",
     "timestamp": 1635958648060,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "comparable-minutes",
    "outputId": "16bf1366-16b1-4dea-dc69-94448726ab74"
   },
   "outputs": [],
   "source": [
    "# Seed value used for achieving reproducibility\n",
    "SEED_VALUE = 1337\n",
    "\n",
    "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
    "import os\n",
    "os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "os.environ['TF_CUDNN_DETERMINISM'] = '1'\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED_VALUE)\n",
    "\n",
    "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(SEED_VALUE)\n",
    "\n",
    "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(SEED_VALUE)\n",
    "\n",
    "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(SEED_VALUE)\n",
    "\n",
    "# Import the Keras backend used for freeing the global state\n",
    "# to avoid clutter\n",
    "from tensorflow.keras import backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "basic-miniature",
   "metadata": {
    "id": "basic-miniature"
   },
   "source": [
    "## Subtask a. Data Preparation and Import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5538b2b1",
   "metadata": {
    "id": "v5WYmolWUWMa"
   },
   "source": [
    "### Importing the Data\n",
    "\n",
    "We adopt the `pandas` Python package to read the train and test comma-separated values (csv) dataset files into 2 `DataFrame` structures. Specifically, we use the `read_csv` functions of the package to carry out the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f87fb9b",
   "metadata": {
    "id": "wuX8-IEbUWw6"
   },
   "outputs": [],
   "source": [
    "# Import the crucial Pandas and Matplotlib packages \n",
    "# used for data preparation and visualisation respectively\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 'Read' the train and test data into Pandas data frames\n",
    "train_df, test_df = pd.read_csv('data/Train.csv'), pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4261034",
   "metadata": {
    "id": "QAdmwOOXuj4-"
   },
   "source": [
    "#### Describing the Data\n",
    "\n",
    "We employ the `DataFrame.describe()` method of the `pandas` library to display some basic statistical details like percentile, mean, std etc. of our data frame. We also show the shapes of the train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23dcfddc",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1635883602849,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "bLWYUuKlUW7T",
    "outputId": "a69e4136-fc6f-4290-cf7c-34132ebb42a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (107085, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip</th>\n",
       "      <th>VehicleSpeed_km_h_</th>\n",
       "      <th>Battery_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>107085.000000</td>\n",
       "      <td>107085.000000</td>\n",
       "      <td>107085.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2398.752832</td>\n",
       "      <td>34.640675</td>\n",
       "      <td>0.264388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>509.159153</td>\n",
       "      <td>22.455519</td>\n",
       "      <td>0.441009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1567.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1949.000000</td>\n",
       "      <td>15.589999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2384.000000</td>\n",
       "      <td>36.270000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2902.000000</td>\n",
       "      <td>52.529999</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3263.000000</td>\n",
       "      <td>103.430000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Trip  VehicleSpeed_km_h_  Battery_Status\n",
       "count  107085.000000       107085.000000   107085.000000\n",
       "mean     2398.752832           34.640675        0.264388\n",
       "std       509.159153           22.455519        0.441009\n",
       "min      1567.000000            0.000000        0.000000\n",
       "25%      1949.000000           15.589999        0.000000\n",
       "50%      2384.000000           36.270000        0.000000\n",
       "75%      2902.000000           52.529999        1.000000\n",
       "max      3263.000000          103.430000        1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the training dataset shape and describe the set\n",
    "print(f'Training data shape: {train_df.shape}\\n')\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ee6bc8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1635883602849,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "lfoVzYBCwAJ9",
    "outputId": "ef85c17b-7205-4218-b360-6bd77319e070"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data shape: (60172, 3)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Trip</th>\n",
       "      <th>VehicleSpeed_km_h_</th>\n",
       "      <th>Battery_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>60172.000000</td>\n",
       "      <td>60172.000000</td>\n",
       "      <td>60172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2449.359320</td>\n",
       "      <td>34.255137</td>\n",
       "      <td>0.257346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>447.700622</td>\n",
       "      <td>22.876331</td>\n",
       "      <td>0.437175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1558.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2105.000000</td>\n",
       "      <td>13.960000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2533.000000</td>\n",
       "      <td>36.369999</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2806.000000</td>\n",
       "      <td>53.590000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3271.000000</td>\n",
       "      <td>84.650002</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Trip  VehicleSpeed_km_h_  Battery_Status\n",
       "count  60172.000000        60172.000000    60172.000000\n",
       "mean    2449.359320           34.255137        0.257346\n",
       "std      447.700622           22.876331        0.437175\n",
       "min     1558.000000            0.000000        0.000000\n",
       "25%     2105.000000           13.960000        0.000000\n",
       "50%     2533.000000           36.369999        0.000000\n",
       "75%     2806.000000           53.590000        1.000000\n",
       "max     3271.000000           84.650002        1.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the test dataset shape and describe the set\n",
    "print(f'Test data shape: {test_df.shape}\\n')\n",
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a24e5",
   "metadata": {
    "id": "hcjSW4EdUW_K"
   },
   "source": [
    "We notice that the dataset consists only of numeric values. There are 107,058 records of train and 60,172 records of test data, each with 2 features &mdash; `Trip` and `VehicleSpeed_km_h_` &mdash; and a target variable `Battery_Status`. Moreover, it is worth noting that the feature value ranges are different (quantities in the 10s and 1000s thus not scaled) for each feature. Hence, we will need to perform some data scaling on the provided data which is detailed in the sections below. The maximum, minimum, mean values etc. are all observable in the data frame shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb33146",
   "metadata": {},
   "source": [
    "### Preparing the Data\n",
    "\n",
    "In the task requirements it is specifically stated that:\n",
    "\n",
    "- **\"For the sake of reducing time for training and running a model, only speed is used to predict the battery status.\"**\n",
    "\n",
    "Therefore, we need to reduce the dimensionality of the train and test data to 1 feature (`VehicleSpeed_km_h_` column) by removing the 'Trip' feature since we only care about how EV speed affects its battery status. We perform this by using the `drop()` function of the `pandas.DataFrame` package as shown in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f33fc2ba",
   "metadata": {
    "id": "YYbCCGEysrCV"
   },
   "outputs": [],
   "source": [
    "# Drop the 'Trip' column from both training and test data frames\n",
    "train_df_reduced = train_df.drop([\"Trip\"], axis=1)\n",
    "test_df_reduced = test_df.drop([\"Trip\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a2b4db",
   "metadata": {
    "id": "rN-xTC_2BZBD"
   },
   "source": [
    "\n",
    "#### Handling Missing Values\n",
    "\n",
    "First, we need to check if there are any missing (`NaN`) values our dataset. This can be evaluated via the `isnull()` or `isna()` functions of the `pandas.DataFrame` structure as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f9caa8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635883603535,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "A9RNIYEbAMY5",
    "outputId": "fb1ffa03-17a7-4b54-bbb9-f628d5729ef2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for null values\n",
    "train_df_reduced.isnull().values.any(),  test_df_reduced.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15a1331",
   "metadata": {
    "id": "UrbeE5ofkgDi"
   },
   "source": [
    "Apparently, there are no missing values in our train and test sets. This is a good thing because e if a dataset is full of `NaN` (junk) values, then the trained model will surely show a poor performance. So taking care of such missing values is indeed an important preprocessing step which is not required in our scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bf5aac",
   "metadata": {
    "id": "I9IwcvsABRsT"
   },
   "source": [
    "#### Visualisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01700f04",
   "metadata": {
    "id": "4dBLBAgaAkzP"
   },
   "source": [
    "Next, we plot some figures to visualise our data.\n",
    "\n",
    "First of all, let us see some data histograms for both the training and test datasets. This will show us the actual data distributions over the `VehicleSpeed_km_h_` feature and the `Battery_Status` target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6257ff5a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1635883604562,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "BTO-RhITwOyi",
    "outputId": "bf3a943a-944e-4843-fe01-c9cf36eadf35"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFTCAYAAACamGBzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6+ElEQVR4nO3de5xcdX3/8de7RK5yCVBXTFKDNVARKkKEWK1duQZQw68ihqIkiqSteE8rQduCCP5CLSKgRSNEgiIBESWVQIzAlp+VhLuEECgBIiQGAuQCAQGDn98f3+/AyWQ2O7s7s2dm9/18POaxc77ne8585mTz3c98L2cUEZiZmZnZwPuTsgMwMzMzG6qciJmZmZmVxImYmZmZWUmciJmZmZmVxImYmZmZWUmciJmZmZmVxImYWRNIijoey/r5GpPzeUb34dhL+vv6fVGIufJ4TtIyST+VdKwk9fG8+0o6XdLODY53maQfdrPvTElRo/4lvTj/6Bz3m/oZqpm1qWFlB2A2SL2zavunwG+A0wtlL/bzNa7Nr7OyD8d+FTivn6/fHx8ClgNbAX8GHAVcDkyR9P6I+H0vz7cvcBrwQ2B1A+Psrf8DPNOL+qNJcf8KeLgZAZlZa3MiZtYEEbGguC3pReCp6vKqOlsAiogNdb7Gk8CTfYzvob4c10B3R8TSwvYPJP0Y+DHw78CnywmrfyLirrJjqFfufXxNRLxUdixmQ5mHJs1KkofmzpI0TdIjwEvAPpK2lnSupHslrZf0uKT/kvQXVcdvMjRZGUqTNFHSkjz0d7ukd1cdu9HQZB4iC0l/L+kMSSslrc2vO7Lq2G0lXSjp6RzfTyX9VT5+cl+vR0T8BLgGOEnStoXX+4qkOyU9I+kpSTdKGle8DsD38+aDhWHP0Xn/pyTdIml1fk8LJB3V1zg3p3poUtLrJc2S9DtJL+br+nNJr5PUCdyUq84vxN2Zj31NHv5cJuml/PNMSa+pes03SZor6XlJqySdI2nKZn43Pi7pftLv21F532avca7Tmc95tKTvFq7nNyVtIekdkn6Vf+cWSzq86vh3SJqff29+L+lhSf/ZmCtv1r7cI2ZWrsmkIal/Ap4DfkcartseOJM07Lgz8EngFklviYjHezjnXwN7Av8KvEAahvy5pNERsbaHY08Ffg18HHgdcA5puK+zUGcGaWjxdOB24GDgsp7eaJ3mAkcDY4Gbc9kI4FzSUOZ2wEeAmyXtHxGLSEO0ZwL/wqtDnvDqkO1o4CJgGanNez/pehwREdfXEZMk1Wor65nP9gPgjcA/A48BHaTrtS1wJ3Ay8G3gM8Bt+Zj78s9ZwLHA10hDl38FfBl4E/B3ObAtgfmk35l/JPWQfgI4ppt43ksaxv0KsIp0TaDna1z0TeBq4MPAe0jXfQvgEODrwIpcdrWkN0bEU5JeC8wDbiX9zj9L+nf5q26vnNlQERF++OFHkx+kP3g/rCoLUuK1TQ/HbkH6w/0s8PlC+eR8jtFVr7MGGF4oG5vr/V2h7BJgWWF7dK7TVfXa/5TL35C39wT+CHyxqt75ud7kHt5LJeY3d7P/8Lz/w5u5FsOAB4Dz6j1vod6f5ON/AVxT579bbO5Ro/4lhe31wGc2c/7OfJ5Dqsr3zuWnV5X/Sy7/y7w9JW8fUKgj0nzEWr8bzwOvr+P3rdY1rsQ6s6r+nbn83YWyv8xlk6p+B/9yoP/v+eFHqz88NGlWruujxsR0pRWECyWtBTaQesteS0qEenJLRKwpbFd6NP6sjmPnVm1XH3sg6Q/9j6vqXVXHuetR6WV6ZTWipEMk3STpadK1+AOwB/VdCyTtn4cDnygcf2i9xwPXAe+o8ZhZx7G3Af8s6bOS9pHqXhX6nvyzesVmZftv8s9xwKMRcWulQkQE8JNuzrsgavSo9vIaX1e1fT/wXET8qqoMYFT++SCwFviupI9IGoWZAZ4jZla2TVY8Sno/cAWwhDQEdSDpD/+TwNZ1nHOjVYMRUVmd2etjeXVlZ+XY3fLPVVX1nqjj3PWo/IFeCSBpP1JyuB44kZR4vIPU49Pj+8l/8G8gDe9+mjQU9g7g+nqOz1ZHxO3VD+pbrfphYA7wReAeYIWkf5PUU9tbuQ1H9Ws8XrV/Nzb9t4Du/z1q/b719hqvqdp+iZRkvSJeXQCwdd5eRxoW/R3wn8CjSnMgP9hNnGZDhueImZUrapRNBJZGxORKQZ6g3dB7ZPVR5Q/564BHCuUdDTr/UaR5bXfk7Q+Semj+NiL+UKkkaThVf/y7MR7YETg2IipzxyguBmimiFhFmgd2sqQ9gUmk+VlPAhdu5tBKQvx6oLjC9fVV+1cCe9U4vrt/j1q/b/29xnWJiLuBD+b5dmNJ8xGvlPS2iLi3Ua9j1m7cI2bWerYl/WEs+ihp7k7ZbiX9Mf9QVXn1dq/l3pEPAN+JiOdz8bbAy2w8VHkQmw6zVnrutqkqryRcxQRjD+Bd/Y23tyLigYj4EqlHae9c3F3clYUKE6vKj88/u/LPBcCfSTqgUiEPf/amp6nea9wQEbEh0m1c/pX0N+gtzXgds3bhHjGz1nM9cLSkc4Gfk3oPPk0Deyf6KiLul/Qj4Kt5eO0O4CDSSkRIE/nrsa+kXYEtSX/w30dK5uaTekoqrgc+B1wi6fukeUv/SlqZV1RZaXiypFmkxOse4JekpPZSSeeQhvK+AjxKkz+IStoxv/5lpDlTfwAmAMNJiwUA/jfH93FJq0mJ2QMRca+ky4HTcw/Sr0k37/1X4PJ4dSXjJcAppBWKX+bVVZPD8/56/j3qvcZ9Jul9pIUFPyP1pG5HWin6LHBLo17HrB05ETNrPd8jzZX6OPD3pAnf7yfdnb8VTCH9Af0iKZG6kTT89nNgXZ3nqEz2f4E0x+lOUu/PVXmyOQARMU/SZ4AvkHp57gVOIK0epFDvN5JOz7GdREqydo+IxZKOB84gzdV6CJhGGrLs7M2b7oMXSO/rJNItLP5IWol4fERck+N+WtKnSMnUf5N6Pd9L6vGaTLq1ycdJ7/d3wNmkRJJ8/EuSDgMuAL5Dmuf1I2AhMJ06/j3qvcb99CDwe1KCtxvp9+c24NDikLHZUKRCm2dm1ieS/ol0R/zREfFo2fEMdZJ+DrwlIv687FjMbPPcI2ZmvZKHmfYG7ib18vw16X5jVzoJG3iSvkDqCXuQdCPgD5EWPfxjmXGZWX2ciJlZbz1Luvv9NNJcnxWkG7qeVmJMQ9mLwOdJc+22IA1/fiIiLi41KjOri4cmzczMzEri21eYmZmZlcSJmJmZmVlJnIiZmZmZlcSJmJmZmVlJnIgNYpJGS4p8Z+5a+78k6aI6znOJpDMbH2HzSOqS9Ike6kyW9Ksmx9F2187MzAaOE7E2IOl6SWfUKJ8g6fHuEq2eRMTXImKzyUpvSXq3pF9LWidptaT/kfSORr6GmVlPJC2T9HtJ6yWtkXStpFF1HLfJB9iB+NC2mXhOlHS/pGclPSFprqTt875efdAr831Y95yItYdZwEfyl/kWfRS4LCKqvyC6FJJ2IH3NzQXAzsAI0texvLi548zMmuT9EfFa0tcqPUFqmwZcXz8sS/ob4GvAcRGxPekL0q9oZGxWPidi7eFnwC6kO5gDIGk46YuSL5U0TdJDkp6WdKWknauOP17So5Keyl8MXDnH6ZJ+WNiu9GatlfSYpMm1gpH0Pkl353q/lvSXedceABFxeUS8HBG/j4hfRMQ9+bjJuYfsW7nH7H5JBxfOu6OkiyWtlLRC0pmStijs/7ikJfnT7TxJbyzsOzSfb52kbwHVSWuPJH1d0q9yHJVYz83v82FJf5XLH5O0StKkOk89PH8af1bSQkn+2hmzARQRLwBXAXsBSDpK0l2Snsn/n08vVL85/1ybe9PeSfoez3fm7bX5HFtJ+o/ctj4h6TuStsn7OiUtl3SKpMeB70u6V9L7Ky8i6TW5TX77ZkJ/B3BLRNyV38fqiJgVEc9KmgIcD3wxx/Vf+byVvwfPSrpP0v/J5W/p5n1sNI2j2Gum5Nzc3j0jaZGkvXv/L2Cb40SsDUTE74ErSV/EW3EscD/pi4uPBv4GeAOwBvh21SneDewJHAz8W/4PuZGc1FxH+sT4p8C+pK+wqa73dmAm6cuodwG+C8yRtBXwv8DLkmZJOiIni9UOJH3x8q6kO7FfXUgcLwE2AG8G3g4cBnwiv+4E4EvA3+b4/h9wed63K3A16UuKd83nf1eN165J0p9I+h7wl8BhEVH5ouQDgXvy+/wRMJvUML4Z+AjwLUmvreMlJpJ6BocDS4Gz6o3NzPpP0rbAh4EFueg5Unu6E/nroCQdnfe9J//cKSJeGxG3AP9ASoheGxE75f3TSR8+9yW1CSOAfyu87OtJIwNvJH0Z/aWkdqPiSGBlJcnqxkLgcElfkfSu3M4CEBEzgMuAf89xVZK8h0gf2ncktTs/lLRbRCzp5n1szmH5euyRz3cs8HQdx1kvOBFrH7OAYyRtnbdPyGX/AHw5IpZHxIvA6blesSv8K7l36jfAb4C31Tj/3wG/zL1Zf4iIpyPi7hr1pgDfjYiFuddrFmnocVxEPENK+gL4HvCkpDmSOgrHrwK+mV/jCtLXsRyV6xwJfC4inouIVcC5pCSG/D7/b0QsyUOxXwP2zQnkkcDiiLgqIv4AfBN4vI5rCvAaUkK3M2kY4/nCvkci4vsR8TJpOGAUcEZEvBgRvwBeIjXAPflpRNya476M1HCbWfP9LPf8rAMOBb4OEBFdEbEoIv6Ye+wvJ32YrYskkdrCz+deqmdJbdLEQrU/Aqfl9uL3wA+BI5WmcECaWvKDzb1ORPw/0ofP/YBrgaclfaM4UlDjmB9HxO/ye7uC9B2kB9T73qr8gfT9pX9B+iaeJRGxso/nsm44EWsTEfEr4Cng6Dy0dQCpl+aNwE/z8NlaYAnwMlBMfopJyfNArV6cUaRPUj15IzC18nr5NUeReuPI/1EnR8RI0hdDv4GUGFWsiI2/V+u3uc4bSUnRysJ5vwu8rvC65xX2rSYNP47Ixz9WOWE+/yvbPXgzMIGUrL5Ute+JwvPf53NXl9XTI1bP9Tezxjs69/xsDXwK+G9Jr5d0oKSbJD0paR3pg96uvTjvnwLbAncU2qTrc3nFk3lIFICI+B3wP8AHJe0EHEH6YLZZEXFd7u3amdRWTSaPFNQi6QS9OnVkLakd7s17K772jcC3SKMsqyTNKCSS1iBOxNrLpaSesI8A83JS8BhwRETsVHhsHRErennux4B65i49BpxV9XrbRsTl1RUj4n7ScGNxTsGI/Gmy4s+A3+XzvgjsWjjvDhHx1sLr/n3V624TEb8GVpKSQeCVT6s9ro7KlgAfA66TtGedx5hZG8m991eTPqS+m/Qhdg4wKiJ2JM2dqrRLtb6AubrsKdIHsbcW2qMd88KA7o6BvPAK+BBpiLDudjr3cN0A3MirbepGr5FHCL5HSjp3yUnovT28t+dISWXF66te9/yI2J80v24P4J/rjdnq40SsvVwKHAKcRPoPDakBOSv/B0TSn+b5VL11GXCIpGMlDZO0i6R9a9T7HvAP+ROlJG2XJ75uL+kvJE2VNDLHMgo4jlfnZUDq4fpMnqj6IdIqoLm5u/sXwDmSdsjztv5cadVQ5X2eKumt+dw75uMhddm/VdLf5iHZz1DVmGxOTiK/BPxSnkhvNujktmoCaZ7mEtJw2+qIeEHSAaSpGRVPkoYV31QoewIYKWlLSEkRqS08V9Lr8muMkHR4D6H8jDTM+FlSe95T3BMkTZQ0PL+HA0hDqJU29YmqOLcjJVtP5uM/xsYfhDd6H9ndwN9K2lbSm4ETC6//jtzWv4aUsL1AujbWQE7E2khELAN+TfrPNicXn5ef/0LSs6T/oAf24dyPkuZaTSUN+91NjblkEXE7KRH8FmlhwFJSVznAs/m1F0p6Lsdybz5nxUJgDOkT5VnAMRFRmfx5ArAlcF8+91WkZedExE+Bs4HZkp7J5z0i73uK9AlzOmki6RjSEEBv3v8s4AzgRkmje3OsmbWs/5K0HniG1N5MiojFwCeBM3Kb+W+kxVAA5HmiZwH/k4f3xpF6oRYDj0t6Klc9hdT+Lcht0i9Ji6K6leeK/QTYnbTAqCdrSO3tg/k9/BD4ekRUhjQvBvbKcf4sIu4DzgFuISVd+7BxW1jrfZxLmu/6BOkDfnG4dAdSwrmGNI3kafI8O2scbTxdx6x5lG6H8YmIeHfZsZiZlUHSvwF7RMRHeqxsQ0KfbjJnZmZmvaN0q54TSSsmzQAPTdogp3STxfU1Ht9p4Gss7uY1jt/MMX/dzTHrGxWXmbUOSSeRFh1dFxE3F8qP76YtWFxetDaQPDRpZmZmVhL3iJmZmZmVxImYmZmZWUnadrL+rrvuGqNHj66r7nPPPcd2223X3IAaoF3iBMfaDO0SJzQu1jvuuOOpiPjTnmsOXYOxratwvM3VbvFC+8Xcm3i7be8ioi0f+++/f9TrpptuqrtumdolzgjH2gztEmdE42IFbo8WaE9a+TEY27oKx9tc7RZvRPvF3Jt4u2vvPDRpZmZmVhInYmZmZmYlcSJmZmZmVhInYmZmmaTP5xv03ivpcklbS9pd0kJJSyVdUfnCZElb5e2lef/ownlOzeUPFL8IWtL4XLZU0rQS3qKZtRgnYmZmgKQRwGeAsRGxN7AFMJH0ZfPnRsSbSV9+fGI+5ERgTS4/N9dD0l75uLcC44H/lLSFpC2Ab5O+rH4v4Lhc18yGMCdiZmavGgZsI2kYsC2wEjgIuCrvnwUcnZ9PyNvk/QdLUi6fHREvRsQjwFLggPxYGhEPR8RLwOxc18yGMCdiZmZARKwA/gN4lJSArQPuANZGxIZcbTkwIj8fQfruQPL+dcAuxfKqY7orN7MhrG1v6Gpm1kiShpN6qHYH1gI/Jg0tlhHLFGAKQEdHB11dXXUdt379+rrrtgLH21ztFi+0X8yNiNeJmJlZcgjwSEQ8CSDpauBdwE6ShuVer5HAilx/BTAKWJ6HMncEni6UVxSP6a58IxExA5gBMHbs2Ojs7KzrDXR1dVFv3VbgeJur3eKF9ou5EfF6aNLMLHkUGCdp2zzX62DgPuAm4JhcZxJwTX4+J2+T99+Y7549B5iYV1XuDowBbgVuA8bkVZhbkib0zxmA92VmLcw9YmZmQEQslHQVcCewAbiL1Ct1LTBb0pm57OJ8yMXADyQtBVaTEisiYrGkK0lJ3Abg5Ih4GUDSp4B5pBWZMyNi8UC9PzNrTUMiEVu0Yh2Tp11bV91l049qcjRm1qoi4jTgtKrih0krHqvrvgB8qJvznAWcVaN8LjC3/5HW5rbOrP14aNLMzMysJD0mYpJmSlol6d6q8k9Luj/fhfrfC+W9uqN0d3etNjMzMxvs6ukRu4SqJdyS3kta5v22iHgr6d47fb2jdHd3rTYzMzMb1HpMxCLiZtJE1KJ/BKZHxIu5zqpc3qs7SueVSd3dtdrMzMxsUOvrHLE9gL/OQ4r/Lekduby3d5Tehe7vWm1mZmY2qPV11eQwYGdgHPAO4EpJb2pYVN3o692mO7aBqfts6LkilHpH33a6o7Bjbbx2iRPaK1Yzs1bW10RsOXB1vnnhrZL+COxK7+8o/TTd37V6E3292/QFl13DOYvqe6vLjq/vnM3QTncUdqyN1y5xQnvFambWyvo6NPkz4L0AkvYAtgSeopd3lM6JXHd3rTYzMzMb1HrsJpJ0OdAJ7CppOelmhzOBmfmWFi8Bk3JS1Zc7Sp9C7btWm5mZmQ1qPSZiEXFcN7s+0k39Xt1ROiJq3rXazMzMbLDznfXNzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwkTsTMzDJJe0q6u/B4RtLnJO0sab6kB/PP4bm+JJ0vaamkeyTtVzjXpFz/QUmTCuX7S1qUjzlfksp4r2bWGpyImZllEfFAROwbEfsC+wPPAz8FpgE3RMQY4Ia8DXAEMCY/pgAXAkjaGTgNOBA4ADitkrzlOicVjhvf/HdmZq3KiZiZWW0HAw9FxG+BCcCsXD4LODo/nwBcGskCYCdJuwGHA/MjYnVErAHmA+Pzvh0iYkFEBHBp4VxmNgQ5ETMzq20icHl+3hERK/Pzx4GO/HwE8FjhmOW5bHPly2uUm9kQNazsAMzMWo2kLYEPAKdW74uIkBRNfv0ppKFOOjo66Orqquu4jm1g6j4b6qpb7zmbaf369S0RR70cb/O1W8yNiNeJmJnZpo4A7oyIJ/L2E5J2i4iVeXhxVS5fAYwqHDcyl60AOqvKu3L5yBr1NxIRM4AZAGPHjo3Ozs7qKjVdcNk1nLOovmZ92fH1nbOZurq6qPe9tQLH23ztFnMj4vXQpJnZpo7j1WFJgDlAZeXjJOCaQvkJefXkOGBdHsKcBxwmaXiepH8YMC/ve0bSuLxa8oTCucxsCHKPmJlZgaTtgEOBvy8UTweulHQi8Fvg2Fw+FzgSWEpaYfkxgIhYLemrwG253hkRsTo//yRwCbANcF1+mNkQ5UTMzKwgIp4Ddqkqe5q0irK6bgAnd3OemcDMGuW3A3s3JFgza3s9Dk1KmilplaR7a+ybKikk7Zq3fXNDMzMzszrVM0fsEmrccFDSKNK8h0cLxb65oZmZmVmdekzEIuJmYHWNXecCXwSKy7h9c0MzMzOzOvVpjpikCcCKiPhN1UhiU29uONjvrdNO909xrI3XLnFCe8VqZtbKep2ISdoW+BJpWHJADfZ767TT/VMca+O1S5zQXrGambWyvtxH7M+B3YHfSFpGuiHhnZJez+ZvbthdeY83NzQzMzMbjHqdiEXEooh4XUSMjojRpOHE/SLicXxzQzMzM7O61XP7isuBW4A9JS3PNzTszlzgYdLNDb9HunEh+UaGlZsb3samNze8KB/zEL65oZmZmQ0RPU6ciojjetg/uvDcNzc0MzMzq5O/a9LMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMwySTtJukrS/ZKWSHqnpJ0lzZf0YP45PNeVpPMlLZV0j6T9CueZlOs/KGlSoXx/SYvyMedLUhnv08xahxMxM7NXnQdcHxF/AbwNWAJMA26IiDHADXkb4AhgTH5MAS4EkLQzcBpwIHAAcFolect1TiocN34A3pOZtTAnYmZmgKQdgfcAFwNExEsRsRaYAMzK1WYBR+fnE4BLI1kA7CRpN+BwYH5ErI6INcB8YHzet0NELIiIAC4tnMvMhignYmZmye7Ak8D3Jd0l6SJJ2wEdEbEy13kc6MjPRwCPFY5fnss2V768RrmZDWHDyg7AzKxFDAP2Az4dEQslncerw5AARERIimYHImkKabiTjo4Ourq66jquYxuYus+GuurWe85mWr9+fUvEUS/H23ztFnMj4nUiZmaWLAeWR8TCvH0VKRF7QtJuEbEyDy+uyvtXAKMKx4/MZSuAzqryrlw+skb9TUTEDGAGwNixY6Ozs7NWtU1ccNk1nLOovmZ92fH1nbOZurq6qPe9tQLH23ztFnMj4vXQpJkZEBGPA49J2jMXHQzcB8wBKisfJwHX5OdzgBPy6slxwLo8hDkPOEzS8DxJ/zBgXt73jKRxebXkCYVzmdkQ1WMiJmmmpFWS7i2UfT0v775H0k8l7VTYd2pemv2ApMML5eNz2VJJ0wrlu0tamMuvkLRlA9+fmVlvfBq4TNI9wL7A14DpwKGSHgQOydsAc4GHgaXA94BPAkTEauCrwG35cUYuI9e5KB/zEHBd89+SmbWyevqwLwG+RVrhUzEfODUiNkg6GzgVOEXSXsBE4K3AG4BfStojH/Nt4FBS9/9tkuZExH3A2cC5ETFb0neAE8nLwM3MBlJE3A2MrbHr4Bp1Azi5m/PMBGbWKL8d2Lt/UZrZYNJjj1hE3Aysrir7RURUZoQu4NV5DxOA2RHxYkQ8QvrUd0B+LI2IhyPiJWA2MCF3zx9EmosBGy8NNzMzMxvUGjFH7OO82r3e2+XcuwBrC0mdl3ObmZnZkNGvVZOSvgxsAC5rTDg9vt6gXtLdTst2HWvjtUuc0F6xmpm1sj4nYpImA+8DDs5zJaD75dx0U/406W7Uw3KvWLfLuWHwL+lup2W7jrXx2iVOaK9YzcxaWZ+GJiWNB74IfCAini/smgNMlLSVpN1J36V2K2nl0Ji8QnJL0oT+OTmBuwk4Jh9fXBpuZmZmNqjVc/uKy4FbgD0lLZd0ImkV5fbAfEl359WORMRi4ErSvXeuB06OiJdzb9enSPfXWQJcmesCnAJ8QdJS0pyxixv6Ds3MzMxaVI/jdRFxXI3ibpOliDgLOKtG+VzSfXeqyx8mrao0MzMzG1J8Z30zMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMzMyuJEzEzMzOzkjgRMzMrkLRM0iJJd0u6PZftLGm+pAfzz+G5XJLOl7RU0j2S9iucZ1Ku/6CkSYXy/fP5l+ZjNfDv0sxahRMxM7NNvTci9o2IsXl7GnBDRIwBbsjbAEcAY/JjCnAhpMQNOA04EDgAOK2SvOU6JxWOG9/8t2NmrcqJmJlZzyYAs/LzWcDRhfJLI1kA7CRpN+BwYH5ErI6INcB8YHzet0NELIiIAC4tnMvMhqBhZQdgZtZiAviFpAC+GxEzgI6IWJn3Pw505OcjgMcKxy7PZZsrX16jfCOSppB62Ojo6KCrq6uuwDu2gan7bKirbr3nbKb169e3RBz1crzN124xNyJeJ2JmZht7d0SskPQ6YL6k+4s7IyJyktY0OfmbATB27Njo7Oys67gLLruGcxbV16wvO76+czZTV1cX9b63VuB4m6/dYm5EvB6aNDMriIgV+ecq4KekOV5P5GFF8s9VufoKYFTh8JG5bHPlI2uUm9kQ1WMiJmmmpFWS7i2UeQWRmQ06kraTtH3lOXAYcC8wB6i0W5OAa/LzOcAJue0bB6zLQ5jzgMMkDc/t42HAvLzvGUnjclt3QuFcZjYE1dMjdgmbrurxCiIzG4w6gF9J+g1wK3BtRFwPTAcOlfQgcEjeBpgLPAwsBb4HfBIgIlYDXwVuy48zchm5zkX5mIeA6wbgfZlZi+pxMkFE3CxpdFXxBKAzP58FdAGnUFhBBCyQVFlB1EleQQQgqbKCqIu8giiXV1YQuWEyswEXEQ8Db6tR/jRwcI3yAE7u5lwzgZk1ym8H9u53sGY2KPR1jtiAriAyMzMzG4z6vWpyIFYQVQz2Jd3ttGzXsTZeu8QJ7RWrmVkr62si9oSk3SJiZS9WEHVWlXfRyxVEg31Jdzst23WsjdcucUJ7xWpm1sr6OjTpFURmZmZm/dRjN5Gky0m9WbtKWk5a/TgduFLSicBvgWNz9bnAkaTVQM8DH4O0gkhSZQURbLqC6BJgG9IkfU/UNzMzsyGhnlWTx3WzyyuIzMzMzPrBd9Y3MzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSOBEzMzMzK4kTMTMzM7OSDCs7AGt/o6dd25TzLpt+VFPOa7Y5krYAbgdWRMT7JO0OzAZ2Ae4APhoRL0naCrgU2B94GvhwRCzL5zgVOBF4GfhMRMzL5eOB84AtgIsiYvqAvjkzazlOxKymnpKrqftsYHKTEjCzkn0WWALskLfPBs6NiNmSvkNKsC7MP9dExJslTcz1PixpL2Ai8FbgDcAvJe2Rz/Vt4FBgOXCbpDkRcd9AvTEzaz0emjQzyySNBI4CLsrbAg4CrspVZgFH5+cT8jZ5/8G5/gRgdkS8GBGPAEuBA/JjaUQ8HBEvkXrZJjT9TZlZS3OPmJnZq74JfBHYPm/vAqyNiA15ezkwIj8fATwGEBEbJK3L9UcACwrnLB7zWFX5gbWCkDQFmALQ0dFBV1dXXcF3bJN6q+tR7zmbaf369S0RR70cb/O1W8yNiNeJmJkZIOl9wKqIuENSZ5mxRMQMYAbA2LFjo7OzvnAuuOwazllUX7O+7Pj6ztlMXV1d1PveWoHjbb52i7kR8fZraFLS5yUtlnSvpMslbS1pd0kLJS2VdIWkLXPdrfL20rx/dOE8p+byByQd3q93ZGbWN+8CPiBpGWnY8CDSxPqdJFWym5HAivx8BTAKIO/fkTRp/5XyqmO6KzezIazPiZikEcBngLERsTdpFVBlwuq5EfFmYA1pQisUJrYC5+Z6VE1sHQ/8Z161ZGY2YCLi1IgYGRGjSW3SjRFxPHATcEyuNgm4Jj+fk7fJ+2+MiMjlE/OHz92BMcCtwG3AmPxhdcv8GnMG4K2ZWQvr72T9YcA2+dPgtsBKGjex1cysFZwCfEHSUtIcsItz+cXALrn8C8A0gIhYDFwJ3AdcD5wcES/neWafAuaRVmVemeua2RDW5zliEbFC0n8AjwK/B35BusdOIye2bmSwT2BtpUmKPV2v3lzTvmrUtWil67o57RIntFesfRERXUBXfv4wNT4cRsQLwIe6Of4s4Kwa5XOBuQ0M1czaXJ8TMUnDSb1ZuwNrgR+ThhabZrBPYG2lSYo93SNs6j4b6r6mfdWof4tWuq6b0y5xQnvFambWyvozNHkI8EhEPBkRfwCuJk12bdTEVjMzM7NBrT9dGo8C4yRtSxqaPJj0tSCVia2zqT2x9RYKE1slzQF+JOkbpLtQVya22hDXm69O8tchmZlZO+rPHLGFkq4C7gQ2AHeRhg2vBWZLOjOXFSe2/iBPbF1NWjFERCyWVJnYuoE8sbWvcVn3mvWdkGZmZtY3/ZrkExGnAadVFTdsYquZmZnZYObvmjQzMzMriRMxMzMzs5I4ETMzMzMriRMxMzMzs5I0946c1nReCWlmZta+3CNmZmZmVhInYmZmZmYlcSJmZmZmVhLPEbNBYXNz5abus2GjLzH31yGZmVmrcI+YmZmZWUmciJmZmZmVxImYmZmZWUmciJmZmZmVxImYmZmZWUmciJmZmZmVxImYmZmZWUmciJmZmZmVxImYmZmZWUmciJmZZZK2lnSrpN9IWizpK7l8d0kLJS2VdIWkLXP5Vnl7ad4/unCuU3P5A5IOL5SPz2VLJU0b8DdpZi3FiZiZ2ateBA6KiLcB+wLjJY0DzgbOjYg3A2uAE3P9E4E1ufzcXA9JewETgbcC44H/lLSFpC2AbwNHAHsBx+W6ZjZEOREzM8siWZ83X5MfARwEXJXLZwFH5+cT8jZ5/8GSlMtnR8SLEfEIsBQ4ID+WRsTDEfESMDvXNbMhyomYmVlB7rm6G1gFzAceAtZGxIZcZTkwIj8fATwGkPevA3Ypllcd0125mQ1Rw/pzsKSdgIuAvUmfGj8OPABcAYwGlgHHRsSa/CnxPOBI4HlgckTcmc8zCfiXfNozI2IWQ9joadeWHYLZkBURLwP75vbtp8BfDHQMkqYAUwA6Ojro6uqq67iObWDqPht6rgh1n7OZ1q9f3xJx1MvxNl+7xdyIePuViJESq+sj4pg8eXVb4EvADRExPU9EnQacQpoTMSY/DgQuBA6UtDNwGjCWlMzdIWlORKzpZ2xmZn0WEWsl3QS8E9hJ0rDc6zUSWJGrrQBGAcslDQN2BJ4ulFcUj+muvPjaM4AZAGPHjo3Ozs66Yr7gsms4Z1F9zfqy4+s7ZzN1dXVR73trBY63+dot5kbE2+ehSUk7Au8BLgaIiJciYi0bz5monktxaZ6DsYDUsO0GHA7Mj4jVOfmaT5rcamY2oCT9ae4JQ9I2wKHAEuAm4JhcbRJwTX4+J2+T998YEZHLJ+ZVlbuTPoDeCtwGjMmrMLckTeif0/Q3ZmYtqz89YrsDTwLfl/Q24A7gs0BHRKzMdR4HOvJzz5kws1a3GzArr278E+DKiPi5pPuA2ZLOBO4ifwDNP38gaSmwmpRYERGLJV0J3AdsAE7OQ55I+hQwD9gCmBkRiwfu7ZlZq+lPIjYM2A/4dEQslHQeaRjyFRERkqI/ARYN9nkTlbHmemMtU2+uadmqY23V+QftNDeinWLtjYi4B3h7jfKHSSseq8tfAD7UzbnOAs6qUT4XmNvvYM1sUOhPIrYcWB4RC/P2VaRE7AlJu0XEyjz0uCrv727OxAqgs6q8q9YLDvZ5E5Wx5sltMFl/6j4b6r6mZauOtRXmxtTSTnMj2ilWM7NW1ue/pBHxuKTHJO0ZEQ8AB5O64e8jzZmYzqZzKT4laTZpsv66nKzNA74maXiudxhwal/jMjMzM+ur3ty54JLx2/X79frbpfFp4LI86fRh4GPkeRWSTgR+Cxyb684l3bpiKen2FR8DiIjVkr5KmsQKcEZErO5nXGZmZmYtr1+JWETcTbrtRLWDa9QN4ORuzjMTmNmfWMzq1ZtPO8umH9XESMzMbKjznfXNzMzMSuJEzMzMzKwkTsTMzMzMSuJEzMzMzKwk7XEjqEGgngniU/fZ0Bb3EDMzM7PGcCJWxSvqzMzMbKB4aNLMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEriRMzMzMysJE7EzMzMzEri21f0Q29udWFmZmZWzT1iZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmBkgaJekmSfdJWizps7l8Z0nzJT2Yfw7P5ZJ0vqSlku6RtF/hXJNy/QclTSqU7y9pUT7mfEka+HdqZq3EiZiZWbIBmBoRewHjgJMl7QVMA26IiDHADXkb4AhgTH5MAS6ElLgBpwEHAgcAp1WSt1znpMJx4wfgfZlZC3MiZmYGRMTKiLgzP38WWAKMACYAs3K1WcDR+fkE4NJIFgA7SdoNOByYHxGrI2INMB8Yn/ftEBELIiKASwvnMrMhqt9fcSRpC+B2YEVEvE/S7sBsYBfgDuCjEfGSpK1IDc/+wNPAhyNiWT7HqcCJwMvAZyJiXn/jMmuE3nyN1bLpRzUxEhtIkkYDbwcWAh0RsTLvehzoyM9HAI8VDlueyzZXvrxGuZkNYY34rsnPkj457pC3zwbOjYjZkr5DSrAuzD/XRMSbJU3M9T6cu/4nAm8F3gD8UtIeEfFyA2IzM+sVSa8FfgJ8LiKeKU7jioiQFAMQwxTScCcdHR10dXXVdVzHNjB1nw111a33nM20fv36loijXo63+Voh5nr/D0Fj4u1XIiZpJHAUcBbwhTzx9CDg73KVWcDppERsQn4OcBXwrVx/AjA7Il4EHpG0lDSv4pb+xGZm1luSXkNKwi6LiKtz8ROSdouIlXl4cVUuXwGMKhw+MpetADqryrty+cga9TcRETOAGQBjx46Nzs7OWtU2ccFl13DOovqa9WXH13fOZurq6qLe99YKHG/ztULMk3sxEnLJ+O36HW9/54h9E/gi8Me8vQuwNiIq6WSx6/2V7vq8f12u3103vpnZgMkfDC8GlkTENwq75gCVlY+TgGsK5Sfk1ZPjgHV5CHMecJik4XmS/mHAvLzvGUnj8mudUDiXmQ1Rfe4Rk/Q+YFVE3CGps2ERbf41m95dX6Z2iRMcay397Z5uhS75erVTrL3wLuCjwCJJd+eyLwHTgSslnQj8Fjg275sLHAksBZ4HPgYQEaslfRW4Ldc7IyJW5+efBC4BtgGuyw8zG8L6MzT5LuADko4EtibNETuPtHJoWO71Kna9V7rxl0saBuxImrTfXff+Jgaiu75MU/fZ0BZxgmOtpb9DPa3QJV+vdoq1XhHxK6C7+3odXKN+ACd3c66ZwMwa5bcDe/cjTDMbZPo8NBkRp0bEyIgYTZpsf2NEHA/cBByTq1V341e694/J9SOXT5S0VV5xOQa4ta9xmZmZmbWLZnQTnALMlnQmcBdpzgX55w/yZPzVpOSNiFgs6UrgPtINFU/2ikkzMzMbChqSiEVEF2lVEBHxMGnVY3WdF4APdXP8WaSVl2ZmZmZDhu+sb2ZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZmZmJXEiZmZmZlYSJ2JmZpmkmZJWSbq3ULazpPmSHsw/h+dySTpf0lJJ90jar3DMpFz/QUmTCuX7S1qUjzlfkgb2HZpZq+lzIiZplKSbJN0nabGkz+byhjVaZmYD7BJgfFXZNOCGiBgD3JC3AY4AxuTHFOBCSG0gcBpwIHAAcFqlHcx1TiocV/1aZjbEDOvHsRuAqRFxp6TtgTskzQcmkxqt6ZKmkRqtU9i40TqQ1CAdWGi0xgKRzzMnItb0IzazATd62rV11102/agmRmJ9FRE3SxpdVTwB6MzPZwFdpDZtAnBpRASwQNJOknbLdedHxGqA3C6Ol9QF7BARC3L5pcDRwHXNe0dm1ur63CMWESsj4s78/FlgCTCC1DjNytVmkRoaKDRauSGqNFqHkxutnHzNx58Szax1dETEyvz8caAjPx8BPFaotzyXba58eY1yMxvC+tMj9or8CfLtwEIa12iZmbWUiAhJ0ezXkTSFNNxJR0cHXV1ddR3XsQ1M3WdDXXXrPWczrV+/viXiqJfjbb5WiLne/0PQmHj7nYhJei3wE+BzEfFMce5poxutgWicytQucYJj7a9av7ut0ADVq51ibYAnJO0WEStzL/6qXL4CGFWoNzKXreDVocxKeVcuH1mj/iYiYgYwA2Ds2LHR2dlZq9omLrjsGs5ZVF+zvuz4+s7ZTF1dXdT73lqB422+Voh5ci+mmVwyfrt+x9uvREzSa0hJ2GURcXUublSjtYmBaJzKNHWfDW0RJzjW/qr1R7AVGqB6tVOsDTAHmARMzz+vKZR/StJs0rzXdbndmwd8rTBB/zDg1IhYLekZSeNIowcnABcM5Bsxs9bTn1WTAi4GlkTENwq7Ko0WbNponZBXT44jN1rAPOAwScNzw3VYLjMzG1CSLgduAfaUtFzSiaQE7FBJDwKH5G2AucDDwFLge8AnAfIk/a8Ct+XHGZWJ+7nORfmYh/BEfbMhrz/dBO8CPgosknR3LvsSqZG6MjdgvwWOzfvmAkeSGqDngY9BarQkVRot2LjRMjMbMBFxXDe7Dq5RN4CTuznPTGBmjfLbgb37E6OZDS59TsQi4ldAdzcjbEijZWZmZjaY+c76ZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWkmFlB2A2FI2edu0mZVP32cDkGuXLph81ECGZmVkJ3CNmZmZmVhInYmZmZmYlcSJmZmZmVhInYmZmZmYlcSJmZmZmVhInYmZmZmYlaZnbV0gaD5wHbAFcFBHTSw7JrCXUutVFd3yri9bnts7MilqiR0zSFsC3gSOAvYDjJO1VblRmZo3lts7MqrVEIgYcACyNiIcj4iVgNjCh5JjMzBrNbZ2ZbaRVhiZHAI8VtpcDB5YUi1nb8jBmy3NbZ2YbaZVErC6SpgBT8uZ6SQ/UeeiuwFPNiapxPtMmcYJjbYaBjlNn9+vwRsX6xgacY9AZiLaun//+jdIW/zcLHG/ztVXM7z27V/HWbO9aJRFbAYwqbI/MZRuJiBnAjN6eXNLtETG27+ENjHaJExxrM7RLnNBesbYYt3UFjre52i1eaL+YGxFvq8wRuw0YI2l3SVsCE4E5JcdkZtZobuvMbCMt0SMWERskfQqYR1rSPTMiFpcclplZQ7mtM7NqLZGIAUTEXGBuk07f6y7+krRLnOBYm6Fd4oT2irWluK3biONtrnaLF9ov5n7Hq4hoRCBmZmZm1kutMkfMzMzMbMgZ1ImYpPGSHpC0VNK0suMpkjRK0k2S7pO0WNJnc/nOkuZLejD/HF52rJDuCC7pLkk/z9u7S1qYr+0VeeJx6STtJOkqSfdLWiLpnS18TT+f/+3vlXS5pK1b5bpKmilplaR7C2U1r6OS83PM90jar4yYh5Ke2jZJW+Xfn6X592l0CWEW4+kp3i/ktvAeSTdIKvW2JvX+7ZD0QUkhqdRVfvXEK+nYwt+bHw10jFWx9PT78Gf57+Nd+XfiyDLiLMSzSXtYtb9/bWBEDMoHaSLsQ8CbgC2B3wB7lR1XIb7dgP3y8+2B/yV95cm/A9Ny+TTg7LJjzbF8AfgR8PO8fSUwMT//DvCPZceYY5kFfCI/3xLYqRWvKenGno8A2xSu5+RWua7Ae4D9gHsLZTWvI3AkcB0gYBywsOzrO5gf9bRtwCeB7+TnE4ErWjze9wLb5uf/2Orx5nrbAzcDC4CxrRwvMAa4Cxiet1/X4vHOqLR9+e/isrLizTFs0h5W7e9XGziYe8Ra+qtEImJlRNyZnz8LLCH9cZ5ASibIP48uJcACSSOBo4CL8raAg4CrcpVWiXNH0n+YiwEi4qWIWEsLXtNsGLCNpGHAtsBKWuS6RsTNwOqq4u6u4wTg0kgWADtJ2m1AAh2a6mnbiv9WVwEH5/+3Zegx3oi4KSKez5sLSPdXK0u9fzu+CpwNvDCQwdVQT7wnAd+OiDUAEbFqgGMsqifeAHbIz3cEfjeA8W2im/awqF9t4GBOxGp9lciIkmLZrDxs8HZgIdARESvzrseBjrLiKvgm8EXgj3l7F2BtRGzI261ybXcHngS+n7u0L5K0HS14TSNiBfAfwKOkBGwdcAeteV0ruruObfN/bZCo53q/Uif/Pq0j/b8tQ29/P04k9S6Upcd489DTqIio/zvFmqee67sHsIek/5G0QNL4AYtuU/XEezrwEUnLSSuMPz0wofVZv9rAwZyItQVJrwV+AnwuIp4p7ovU51nqslZJ7wNWRcQdZcZRp2Gk7uMLI+LtwHOkIbRXtMI1BcjzqyaQksc3ANsBZTaOvdIq19EGF0kfAcYCXy87lu5I+hPgG8DUsmPphWGk4clO4Djge5J2KjOgHhwHXBIRI0nDfj/I131QGrRvjDq/SqRMkl5DSsIui4irc/ETlS7N/LPMLmSAdwEfkLSM1IV8EHAeqeu1ch+6Vrm2y4HlEbEwb19FSsxa7ZoCHAI8EhFPRsQfgKtJ17oVr2tFd9ex5f+vDTL1XO9X6uTfpx2Bpwckuk3V9fsh6RDgy8AHIuLFAYqtlp7i3R7YG+jK7eI4YE6JE/brub7LgTkR8YeIeIQ0J3nMAMVXrZ54TyTNlyUibgG2Jn0HZavqVxs4mBOxlv4qkTxf42JgSUR8o7BrDjApP58EXDPQsRVFxKkRMTIiRpOu4Y0RcTxwE3BMrlZ6nAAR8TjwmKQ9c9HBwH202DXNHgXGSdo2/y5UYm2561rQ3XWcA5yQVw6NA9YVhjCt8epp24r/VseQ/t+W1YPZY7yS3g58l5SElf1BabPxRsS6iNg1IkbndnEBKe7bywm3rt+Hn5F6w5C0K2mo8uEBjLGonngfJbWJSHoLKRF7ckCj7J3+tYFlrkRo9oPUpfm/pBUaXy47nqrY3k0a2rkHuDs/jiTN47gBeBD4JbBz2bEWYu7k1VWTbwJuBZYCPwa2Kju+HNe+wO35uv4MGN6q1xT4CnA/cC/wA2CrVrmuwOWkuWt/IH2aPrG760haKfTt/P9sESWuIBsqj1ptG3AGKSGA9Ifrx/n36FbgTS0e7y+BJwpt4ZxWjreqblfZv/N1XF+RhlPvy/9HJ7Z4vHsB/0NaUXk3cFjJ8dZqD/8B+IfC9e1zG+g765uZmZmVZDAPTZqZmZm1NCdiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiVxImZmZmZWEidiZmZmZiX5/yLYlPrV9dF2AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training data histograms\n",
    "train_df_reduced.hist(bins=20, figsize=(10,5))\n",
    "plt.suptitle(\"Training Data Histograms\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b072e31",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 426,
     "status": "ok",
     "timestamp": 1635883604984,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "9fxKwNq1y27X",
    "outputId": "eead9282-7d40-4d05-8013-4a003d97af4f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAAFTCAYAAACamGBzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAvXElEQVR4nO3de5glVX3v//dHRkBUbqITZDiCBzRBT+Jlgnj0JB1RQPQIMWrwEsAQiZckJuovojmPGJVEExTvRhQCeAEJos5RFBHpY9SAgiAIiIygMshNZriMCop+f3/Uatk03TO7p7undve8X8+zn961alXVd+3dXf3da9XalapCkiRJG999+g5AkiRpU2UiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk9MRGTRlCSGuLxgzk4zmOSvDHJ9kPWHx84/q+SrElyUZL3JHnULOI4NMmfb+j20+xzrMX51GnWr0pywhT1x2ZwjAOTvGrWwUraZC3pOwBJU3ripOVPAd8G3jhQduccHOcxwJHAR4HVQ25zMfCX7fnWwKOBPwdemuSVVfX+DYjjULrz0fEbsO1c+Rbd637ZDLY5EHgq8I75CEjS4mciJo2gqjp3cDnJncBPJpf35PZJcXwxyXuAk4H3JPlmVX2zp9g2WFXdBozC6zuUJFtU1Vwk45J65NCktEAl2TXJx5LclOTONkT4x5PqPCLJp5LcmOSOJD9K8h9JliQ5FPj3VvXKgSHHXWYaS1X9Eng5cBfwNwPH3y3JR5JcneTnSa5K8oEk2w3UGQf+EHjSQAzjbd2Dk3wwyfeS/CzJNUk+nmSnmca4PlMNTSbZN8nXk9yaZG2SK5K8oa07ATgE2Gmq4eIkj2yv/S2t7ecm2W+K4z4/yXfb+3NJkme1IeDxKWJ7dpIPJbkJuKGtW+9rPBFvG45d3tr089aeZ7T1r0rygyS3JflMkgdP2v6VSS5v261Jcv7k3zdJM2ePmLQAJdkZOA+4Efg74CbgT4FPJjmwqla0qp8D1gAvA34C7ATsT/ch7HPAW4D/AzwXWNW2uW5DYqqqG5OcDzxpoPihwDXA37Y4Hg68HjiDu4dfX043NLoZdw953tZ+bg/cAbyutfGhwKuBryX57aq6Y4jQ7pNkxue6JA8HVgCnAW8CfgHs3toA8GbgwcDvA89qZXe2bR8KfBW4Hfgr4FbgFcDnkjyzqj7f6j0N+Fg7zqva/t4JbAl8b4qw3gN8HvizVgeGe40nbA2cBBwN/Bj4B7rfmfcBj2gxLm0xvA94XovzhcDb2+vwn8D9gN+le38kzUZV+fDhY8QfwA+Ajw4sH0eXmDxoUr2zgIva8x2AAp61jv0e2ursNmQc48BX17H+ZODn61i/BHhyO+Zjh93vQL3NgJ3b9n+8nrpjrd66HidMUX+sLT+nLW+9jmOcAKyaovxout7B3SbFfgXwrYGyrwPfATJQ9vh23PEpYvvUEK/RdK/xCa3sDwbKfreVXQFsNlD+DuCXE2XAewfj9uHDx9w9HJqUFqb96Ho8bm3DjEtar8+ZwO8l2Rq4GbgKeGuSlyTZfSPEFbp/7N1CsnmS17eht5/T/XP/z7b6kUPtMHlZkm8nWUuX3PxoJtvT9fL8/hSPG9ez3UUt3lOSPCfJQ4Y8HsAfAOdW1cqJgqr6FV2i+pgkWyfZDFgOfLKqaqDeBcDV0+z3U5MLZvga/7SqvjKw/N3280stvsHyJcCObfmbLe73JHlqkq2mb7qkmTARkxamhwAH0/3THXz8a1v/oPbP/WnA+cA/A99r1w+9bB7j2pl7Dm3+M91Mz48CzwD2BJ7d1m3JeiT5a+D9wJfadnsCew27ffO9qjp/8oPu9ZpWS6L2pTtPfgS4vl3n9YdDHHN7ph7ivZ4uWd2OrsfyvkydEN4wzX6n2udMXuNbBheq6hft6ZpJ9SbKJ7Y/iW54+wl0yf7qJKdvyPWEku7Ja8Skhelmul6Pt02z/scAVXUVcHCSAL9Hd73S+5P8oNp1SnOl9RgtB04ZKD4IOKmq3jJQ7wEz2O1BwNlV9eqB7XedbazDqqpzgHOSbEF37dub6K7z2qWqfrKOTVcDvzVF+W/R9RiuAX5KlwxO1dO2lLt7/u4R0hRls32N16sl9R8EPtgmAexDd83YJ+iSM0kbyB4xaWH6At31PZdO1dtTk77WoDoX0V0QDt13f8Hd30V2v9kEk+S+dD1XS4B3D6zainv3PL14il3cOU0Mw24/r6rqzqr6MvAvwP2BiWRwurj/H7DXYI9RG4r8U+DCqrqtDQWeD/xJS5Qn6j1+YP/D2KivUVWtqapPAKdy9++RpA1kj5i0ML0B+AbwlSTvpbuYfzu6f4wPr6o/T/K7wLvoei1W0l0sfijddVZfbvuZ+PLSVyQ5ke4f+sUDQ1ZTeWCSieHBBwL/g+4f/yOBl7drnCZ8ATgkySUthmcD/3OKfV4GvDzJnwLfp/uusiva9q9N8vrW3qfQXUQ/75K8lO5arzPoZiXuQDd788d0F9hPxL19G+49H7ijqi4BjqF7rc9KciTdLNCX081MfMbAYY4Evgh8Ksmx7RhvpBvC/PWQoQ77Gm+wFtvtwH/RDaU+gm7m5hfn8jjSpshETFqAqupHSZbT/dP+J7qvPbiZLkE4sVW7nm5461XAMrqvgbgEeOZEslRV307yRuBw4CV0veS70iV20/ldun/IRffP+Wq6WY8HVdWlk+r+Nd01UUe15TOA59MlVYPeRpfIfRh4AF2P0hjdUOC2dF/RsWUr35duEsJ8+zbwdLprsB5CN9z4VeCFVfXzVufDdNes/VOL84fALlX14yRPpmvXB4At6C7+f0ZVfWHiAFV1VvtqiCPpLsRfSff1HG+g+8qLYQz7Gs/G1+iS7T8DtqFLRj9KF7ekWcjAZB1JUs+SLKNLyI6qqjf3HY+k+WUiJkk9SXI/uu/s+hLdF+4+HPh7uov1H1VVG/TlupIWDocmJak/v6KbSfle4EF0Myn/E3iuSZi0abBHTJIkqSd+fYUkSVJPTMQkSZJ6YiImSZLUExMxSZKknpiILWJJdklSSaacHZvk9Uk+PMR+TkjylvXVGyVJxpP8xXrqHJrkq/Mcx4J77SRJG4+J2AKQ5AtJ3jRF+QFJrp8u0VqfqvqnqlpnsjJTSZ6c5OtJbk2yOsnXkvz+XB5DktYnyQ+S/DzJ2iRrknwuyc5DbHevD7Ab40PbOuI5LMl3k9ye5IYkZyR5YFs3ow96fbZD0zMRWxhOBF40eGPg5s+Aj1XVXT3EdC9JtgY+C7wH2B7YCfhH7r6xtCRtTP+7qh4A7AjcQHdu2ug29MNykj+ku33W86vqgcDv0N07VouIidjC8Gm6L3v8XxMFSbYDngmclOSIJN9PcnOSU5NsP2n7Fyb5UZKfJPmHgX28MclHB5YnerNuSXJNkkOnCibJM5Nc1Op9vd1cGrobAVNVJ1fVr6rq51X1xaq6uG13aOshe2/rMftukr0H9rtNkuOSXJfk2iRvSbLZwPo/T3J5+3R7ZpKHDax7Wtvfre0m2JOT1vVK8q9JvtrimIj1mNbOq5L8z1Z+TZIbkxwy5K63a5/Gb09yXpL/PtPYJG24qroDOA3YAyDJM5JcmOS29vf8xoHqX2k/b2m9aU8E/g14Ylu+pe1jiyRHt3PrDUn+rd0pgSRjSVYleW2S64F/T/KdJP974iBJ7tvOyY9dR+i/D/xXVV3Y2rG6qk6sqtuTHA68EPj7Ftf/bfud+H9we5LLkvxxK/+dadpxj8s4BnvN0jmmne9uS3JJkkfP/B3QupiILQDtBsOnAgcPFD8P+C7djZEPBP4QeCiwBnjfpF08me6GynsDb2h/kPfQkprP031ifDDwGLqbFE+u91jgeOAv6ZLDDwIrkmwBfA/4VZITkzy9JYuTPQH4PrAD3Q2DTx9IHE8A7gJ2Ax4L7AP8RTvuAcDrgWe3+P4TOLmt2wE4Hfg/bb/fB540xbGnlOQ+ST5EdzPrfapq4mbLTwAubu38OHAK3YlxN+BFwHuTPGCIQxxE1zO4He0egsPGJmn2kmwF/Clwbiv6Kd35dFvgGcDLkhzY1v1B+7ltVT2gqv4LeCldQvSAqtq2rX8r3YfPx9CdE3aiu1n7hN+iGxl4GHA4cBLdeWPC/sB1E0nWNM4D9k3yj0me1M6zAFTVscDHgH9pcU0ked+n+9C+Dd1556NJdqyqy6dpx7rs016PR7T9PQ+4eYjtNAMmYgvHicBzkmzZlg9uZS8F/qGqVlXVncAbW73BrvB/bL1T3wa+DfzeFPt/AfCl1pv1y6q6uaoumqLe4cAHq+q81ut1It3Q415VdRtd0lfAh4CbkqxIsnRg+xuBd7ZjfAK4AnhGq7M/8LdV9dOquhE4hi6JobXzn6vq8jYU+0/AY1oCuT9waVWdVlW/BN4JXD/EawpwX7qEbnu6YYyfDay7uqr+vap+RTccsDPwpqq6s6q+CPyC7gS8Pp+qqm+0uD9Gd+KWNP8+3Xp+bgWeBvwrQFWNV9UlVfXr1mN/Mt2H2aEkCd258O9aL9XtdOekgwaq/Ro4sp0vfg58FNg/3SUc0F1a8pF1Haeq/pPuw+fjgM8BNyd5x+BIwRTb/EdV/bi17RPAlcCew7Ztkl8CDwR+m+5OPJd76625ZyK2QFTVV+luCnxgG9rak66X5mHAp9rw2S3A5XT3rxtMfgaTkp8BU/Xi7Ez3SWp9Hga8euJ47Zg70/XG0f5QD62qZcCjW/k7B7a/tu55X60ftjoPo0uKrhvY7weBhwwc910D61bTDT/u1La/ZmKHbf+/WV6P3YAD6JLVX0xad8PA85+3fU8uG6ZHbJjXX9LcO7D1/GwJ/BXw/5L8VpInJDknyU1JbqX7oLfDDPb7YGAr4IKBc9IXWvmEm9qQKABV9WPga8CfJNkWeDrdB7N1qqrPt96u7enOVYfSRgqmkuTg3H3pyC105+GZtG3w2F+muw/q+4Abkxw7kEhqjpiILSwn0fWEvQg4syUF1wBPr6ptBx5bVtW1M9z3NcAw1y5dAxw16XhbVdXJkytW1XfphhsHrynYqX2anPDfgB+3/d4J7DCw362r6lEDx/3LSce9X1V9HbiOLhkEfvNpdb2zo5rLgRcDn0/yyCG3kbSAtN770+k+pD6Z7kPsCmDnqtqG7tqpifPSVDdgnlz2E7oPYo8aOB9t0yYGTLcNtIlXwHPphgiHPk+3Hq6zgS9z9zn1HsdoIwQfoks6H9SS0O+sp20/pUsqJ/zWpOO+u6oeT3d93SOA/2/YmDUcE7GF5STgqcBL6P6goTuBHNX+AEny4HY91Ux9DHhqkuclWZLkQUkeM0W9DwEvbZ8ok+T+7cLXByb57SSvTrKsxbIz8Hzuvi4Duh6uv2kXqj6XbhbQGa27+4vA25Ns3a7b+u/pZg1NtPN1SR7V9r1N2x66LvtHJXl2G5L9GyadTNalJZGvB74UL6SXFp12rjqA7jrNy+mG21ZX1R1J9qS7NGPCTXTDig8fKLsBWJZkc+iSIrpz4TFJHtKOsVOSfdcTyqfphhlfSXc+X1/cByQ5KMl2rQ170g2hTpxTb5gU5/3pkq2b2vYv5p4fhO/RjuYi4NlJtkqyG3DYwPF/v53r70uXsN1B99poDpmILSBV9QPg63R/bCta8bva8y8muZ3uD/QJG7DvH9Fda/VqumG/i5jiWrKqOp8uEXwv3cSAlXRd5QC3t2Ofl+SnLZbvtH1OOA/Yne4T5VHAc6pq4uLPg4HNgcvavk+jm3ZOVX0KeBtwSpLb2n6f3tb9hO4T5lvpLiTdnW4IYCbtPxF4E/DlJLvMZFtJI+v/JlkL3EZ3vjmkqi4FXg68qZ0z30A3GQqAdp3oUcDX2vDeXnS9UJcC1yf5Sav6Wrrz37ntnPQluklR02rXin0S2JVugtH6rKE7317Z2vBR4F+ramJI8zhgjxbnp6vqMuDtwH/RJV3/g3ueC6dqxzF017veQPcBf3C4dGu6hHMN3WUkN9Ous9PcyT0v15HmT7qvw/iLqnpy37FIUh+SvAF4RFW9aL2VtUnYoC+ZkyRJM5Puq3oOo5sxKQEOTWqRS/cli2unePzbHB7j0mmO8cJ1bPO/ptlm7VzFJWl0JHkJ3aSjz1fVVwbKXzjNueDS/qLVxuTQpCRJUk/sEZMkSeqJiZgkSVJPFuzF+jvssEPtsssuQ9X96U9/yv3vf//5DWgjsj2jzfYM74ILLvhJVT14/TU3XYv5XGe888t4599MYp7ufLdgE7FddtmF888/f6i64+PjjI2NzW9AG5HtGW22Z3hJfjgvO15EFvO5znjnl/HOv5nEPN35zqFJSZKknpiISZIk9cRETJIkqScmYpIkST0xEZMkSeqJiZgkSVJP1puIJTk+yY1JvjNQtn2Ss5Jc2X5u18qT5N1JVia5OMnjBrY5pNW/MskhA+WPT3JJ2+bdSTLXjZQkSRpFw/SInQDsN6nsCODsqtodOLstAzwd2L09Dgc+AL+54/yRwBOAPYEjJ5K3VuclA9tNPpYkSdKitN5ErN0lfvWk4gOAE9vzE4EDB8pPqs65wLZJdgT2Bc6qqtVVtQY4C9ivrdu6qs6t7u7jJw3sS5IkaVHb0GvEllbVde359cDS9nwn4JqBeqta2brKV01RLkmStOjN+hZHVVVJai6CWZ8kh9MNebJ06VLGx8eH2m7t2rVD110IbM9osz2SpGFtaCJ2Q5Idq+q6Nrx4Yyu/Fth5oN6yVnYtMDapfLyVL5ui/pSq6ljgWIDly5fXsPd3Gj/97Yz9+DVD1eUFGyWnnJWFeD+udbE9o22xtWdRW30BfPyPhqu7AM510qZgQ4cmVwATMx8PAT4zUH5wmz25F3BrG8I8E9gnyXbtIv19gDPbutuS7NVmSx48sC9JkqRFbb09YklOpuvN2iHJKrrZj28FTk1yGPBD4Hmt+hnA/sBK4GfAiwGqanWSNwPfbPXeVFUTEwBeTjcz837A59tDkiRp0VtvIlZVz59m1d5T1C3gFdPs53jg+CnKzwcevb44JEmSFhu/WV+SJKknJmKSJEk9MRGTJEnqiYmYJElST0zEJEmSemIiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk9MRGTJEnqiYmYJElST0zEJEmSemIiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk9MRGTJEnqiYmYJA1IslmSC5N8ti3vmuS8JCuTfCLJ5q18i7a8sq3fZWAfr2vlVyTZd6B8v1a2MskRG71xkkaOiZgk3dMrgcsHlt8GHFNVuwFrgMNa+WHAmlZ+TKtHkj2Ag4BHAfsB72/J3WbA+4CnA3sAz291JW3CTMQkqUmyDHgG8OG2HOApwGmtyonAge35AW2Ztn7vVv8A4JSqurOqrgZWAnu2x8qquqqqfgGc0upK2oSZiEnS3d4J/D3w67b8IOCWqrqrLa8CdmrPdwKuAWjrb231f1M+aZvpyiVtwpb0HYAkjYIkzwRurKoLkoz1HMvhwOEAS5cuZXx8fKjt1t5nGeNbHj3cQYbc53xau3bt0G0bBcY7vxZavDA3MZuISVLnScCzkuwPbAlsDbwL2DbJktbrtQy4ttW/FtgZWJVkCbANcPNA+YTBbaYrv4eqOhY4FmD58uU1NjY2VAPGT387Y3e8Zqi6jNVw9ebR+Pg4w7ZtFBjv/Fpo8cLcxOzQpCQBVfW6qlpWVbvQXWz/5ap6IXAO8JxW7RDgM+35irZMW//lqqpWflCbVbkrsDvwDeCbwO5tFubm7RgrNkLTJI0we8Qkad1eC5yS5C3AhcBxrfw44CNJVgKr6RIrqurSJKcClwF3Aa+oql8BJPkr4ExgM+D4qrp0o7ZE0sgxEZOkSapqHBhvz6+im/E4uc4dwHOn2f4o4Kgpys8AzpjDUCUtcA5NSpIk9cRETJIkqScmYpIkST0xEZMkSeqJiZgkSVJPTMQkSZJ6YiImSZLUExMxSZKknpiISZIk9cRETJIkqScmYpIkST0xEZMkSeqJiZgkSVJPTMQkSZJ6YiImSZLUk1klYkn+LsmlSb6T5OQkWybZNcl5SVYm+USSzVvdLdryyrZ+l4H9vK6VX5Fk31m2SZIkaUHY4EQsyU7A3wDLq+rRwGbAQcDbgGOqajdgDXBY2+QwYE0rP6bVI8kebbtHAfsB70+y2YbGJUmStFDMdmhyCXC/JEuArYDrgKcAp7X1JwIHtucHtGXa+r2TpJWfUlV3VtXVwEpgz1nGJUmSNPI2OBGrqmuBo4Ef0SVgtwIXALdU1V2t2ipgp/Z8J+Catu1drf6DBsun2EaSJGnRWrKhGybZjq43a1fgFuA/6IYW502Sw4HDAZYuXcr4+PhQ2629zzLGtzx6uIMMuc8+rV27dui2LwS2Z7QttvZI0ijZ4EQMeCpwdVXdBJDkdOBJwLZJlrRer2XAta3+tcDOwKo2lLkNcPNA+YTBbe6hqo4FjgVYvnx5jY2NDRXo+OlvZ+yO1wzXqrEarl6PxsfHGbbtC4HtGW2LrT2SNEpmc43Yj4C9kmzVrvXaG7gMOAd4TqtzCPCZ9nxFW6at/3JVVSs/qM2q3BXYHfjGLOKSJElaEDa4R6yqzktyGvAt4C7gQrreqs8BpyR5Sys7rm1yHPCRJCuB1XQzJamqS5OcSpfE3QW8oqp+taFxSZIkLRSzGZqkqo4EjpxUfBVTzHqsqjuA506zn6OAo2YTiyRJ0kLjN+tLkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkoAkWyb5RpJvJ7k0yT+28l2TnJdkZZJPJNm8lW/Rlle29bsM7Ot1rfyKJPsOlO/XylYmOWKjN1LSyDERk6TOncBTqur3gMcA+yXZC3gbcExV7QasAQ5r9Q8D1rTyY1o9kuwBHAQ8CtgPeH+SzZJsBrwPeDqwB/D8VlfSJsxETJKA6qxti/dtjwKeApzWyk8EDmzPD2jLtPV7J0krP6Wq7qyqq4GVwJ7tsbKqrqqqXwCntLqSNmEmYpLUtJ6ri4AbgbOA7wO3VNVdrcoqYKf2fCfgGoC2/lbgQYPlk7aZrlzSJmxJ3wFI0qioql8Bj0myLfAp4Lf7iCPJ4cDhAEuXLmV8fHyo7dbeZxnjWx493EGG3Od8Wrt27dBtGwXGO78WWrwwNzGbiEnSJFV1S5JzgCcC2yZZ0nq9lgHXtmrXAjsDq5IsAbYBbh4onzC4zXTlk49/LHAswPLly2tsbGyouMdPfztjd7xmqLqM1XD15tH4+DjDtm0UGO/8WmjxwtzE7NCkJAFJHtx6wkhyP+BpwOXAOcBzWrVDgM+05yvaMm39l6uqWvlBbVblrsDuwDeAbwK7t1mYm9Nd0L9i3hsmaaTZIyZJnR2BE9vsxvsAp1bVZ5NcBpyS5C3AhcBxrf5xwEeSrARW0yVWVNWlSU4FLgPuAl7RhjxJ8lfAmcBmwPFVdenGa56kUWQiJklAVV0MPHaK8qvoZjxOLr8DeO40+zoKOGqK8jOAM2YdrKRFw6FJSZKknpiISZIk9cRETJIkqScmYpIkST0xEZMkSeqJiZgkSVJPTMQkSZJ6YiImSZLUExMxSZKknswqEUuybZLTknw3yeVJnphk+yRnJbmy/dyu1U2SdydZmeTiJI8b2M8hrf6VSQ6Z/oiSJEmLx2x7xN4FfKGqfhv4Pbob5B4BnF1VuwNnt2WAp9Pd/HZ34HDgAwBJtgeOBJ5AdxuRIyeSN0mSpMVsgxOxJNsAf0C7AW5V/aKqbgEOAE5s1U4EDmzPDwBOqs65wLZJdgT2Bc6qqtVVtQY4C9hvQ+OSJElaKGbTI7YrcBPw70kuTPLhJPcHllbVda3O9cDS9nwn4JqB7Ve1sunKJUmSFrUls9z2ccBfV9V5Sd7F3cOQAFRVJanZBDgoyeF0w5osXbqU8fHxobZbe59ljG959HAHGXKffVq7du3QbV8IbM9oW2ztkaRRMptEbBWwqqrOa8un0SViNyTZsaqua0OPN7b11wI7D2y/rJVdC4xNKh+f6oBVdSxwLMDy5ctrbGxsqmr3Mn762xm74zVD1WVszvLGeTM+Ps6wbV8IbM9oW2ztkaRRssFDk1V1PXBNkke2or2By4AVwMTMx0OAz7TnK4CD2+zJvYBb2xDmmcA+SbZrF+nv08okSZIWtdn0iAH8NfCxJJsDVwEvpkvuTk1yGPBD4Hmt7hnA/sBK4GetLlW1OsmbgW+2em+qqtWzjEuSJGnkzSoRq6qLgOVTrNp7iroFvGKa/RwPHD+bWCRJkhYav1lfkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJEpBk5yTnJLksyaVJXtnKt09yVpIr28/tWnmSvDvJyiQXJ3ncwL4OafWvTHLIQPnjk1zStnl3kmz8lkoaJSZiktS5C3h1Ve0B7AW8IskewBHA2VW1O3B2WwZ4OrB7exwOfAC6xA04EngCsCdw5ETy1uq8ZGC7/TZCuySNMBMxSQKq6rqq+lZ7fjtwObATcABwYqt2InBge34AcFJ1zgW2TbIjsC9wVlWtrqo1wFnAfm3d1lV1blUVcNLAviRtokzEJGmSJLsAjwXOA5ZW1XVt1fXA0vZ8J+Cagc1WtbJ1la+aolzSJmxJ3wFI0ihJ8gDgk8DfVtVtg5dxVVUlqY0Qw+F0w50sXbqU8fHxobZbe59ljG959HAHGXKf82nt2rVDt20UGO/8WmjxwtzEbCImSU2S+9IlYR+rqtNb8Q1Jdqyq69rw4o2t/Fpg54HNl7Wya4GxSeXjrXzZFPXvpaqOBY4FWL58eY2NjU1V7V7GT387Y3e8Zqi6jM17Prle4+PjDNu2UWC882uhxQtzE7NDk5JENwsSOA64vKreMbBqBTAx8/EQ4DMD5Qe32ZN7Abe2IcwzgX2SbNcu0t8HOLOtuy3JXu1YBw/sS9Imyh4xSeo8Cfgz4JIkF7Wy1wNvBU5NchjwQ+B5bd0ZwP7ASuBnwIsBqmp1kjcD32z13lRVq9vzlwMnAPcDPt8ekjZhJmKSBFTVV4Hpvtdr7ynqF/CKafZ1PHD8FOXnA4+eRZiSFhmHJiVJknpiIiZJktQTEzFJkqSezDoRS7JZkguTfLYt75rkvHYvtU8k2byVb9GWV7b1uwzs43Wt/Iok+842JkmSpIVgLnrEXkl3K5AJbwOOqardgDXAYa38MGBNKz+m1aPdy+0g4FF09117f5LN5iAuSZKkkTarRCzJMuAZwIfbcoCnAKe1KpPvyzZxv7bTgL1b/QOAU6rqzqq6mm4q+J6ziUuSJGkhmG2P2DuBvwd+3ZYfBNxSVXe15cF7qf3m/mtt/a2t/nT3ZZMkSVrUNvh7xJI8E7ixqi5IMjZnEa37mJvE/dfWZyHej2tdRro9qy8Yvu72jwdGvD0bYLG1R5JGyWy+0PVJwLOS7A9sCWwNvAvYNsmS1us1eC+1ifuyrUqyBNgGuJnp79d2L5vK/dfWZyHej2tdRro9H/+j4eu2352Rbs8GWGztkaRRssFDk1X1uqpaVlW70F1s/+WqeiFwDvCcVm3yfdkm7tf2nFa/WvlBbVblrsDuwDc2NC5JkqSFYj5ucfRa4JQkbwEupLuJLu3nR5KsBFbTJW9U1aVJTgUuA+4CXlFVv5qHuCRJkkbKnCRiVTUOjLfnVzHFrMequgN47jTbHwUcNRexaMR9fIpb+W159NRDgC8Y/WFiSZJmw2/WlyRJ6sl8DE1Ko22qXjlJknpgj5gkSVJPTMQkSZJ64tCkRtdMhhC9sF+StADZIyZJktQTEzFJkqSeODSpxWEUZkJOxDDd96INcihVkoSJmObCKCRBkiQtQCZikiRJE2bSufDQc2Z9OK8RkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPfELXTU1vy1fkqR5Z4+YJElST+wR25TYyyVJ0kixR0ySJKkn9ohJfZhJ7+QLav7ikCT1yh4xSZKknpiISZIk9cShyYXOC/AlSVqw7BGTJEnqiYmYJElST0zEJEmSemIiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk98QtdR9H6vqR1y6Ph43+0cWKRJEnzxh4xSZKknpiISZIk9cRETJKaJMcnuTHJdwbKtk9yVpIr28/tWnmSvDvJyiQXJ3ncwDaHtPpXJjlkoPzxSS5p27w7iTeLlTZxXiM22Uxuov2Cmr84JPXhBOC9wEkDZUcAZ1fVW5Mc0ZZfCzwd2L09ngB8AHhCku2BI4HlQAEXJFlRVWtanZcA5wFnAPsBn98I7ZI0ouwRk6Smqr4CrJ5UfABwYnt+InDgQPlJ1TkX2DbJjsC+wFlVtbolX2cB+7V1W1fVuVVVdMnegUjapJmISdK6La2q69rz64Gl7flOwDUD9Va1snWVr5qiXNImzKFJSRpSVVWSeb8mIcnhwOEAS5cuZXx8fKjt1t5nGeNbHj3cQYbc53xau3bt0G0bBcY7v0Ym3mH/hpibmE3ENpaZXHsmaZTckGTHqrquDS/e2MqvBXYeqLeslV0LjE0qH2/ly6aofy9VdSxwLMDy5ctrbGxsqmr3Mn762xm74zVD1WWs/2tcx8fHGbZto8B459fIxDuD7+kc3/6cWce8wUOTSXZOck6Sy5JcmuSVrXzOZhhJ0ghYAUyclw4BPjNQfnA7t+0F3NqGMM8E9kmyXTv/7QOc2dbdlmSvNlvy4IF9SdpEzaZH7C7g1VX1rSQPpJsZdBZwKHM3w2i02cslLSpJTqbrzdohySq6c9NbgVOTHAb8EHheq34GsD+wEvgZ8GKAqlqd5M3AN1u9N1XVxASAl9PNzLwf3WxJZ0xKm7gNTsTap7vr2vPbk1xOd+HpAdzdLX8iXZf8axmYYQScm2RihtEYbYYRQEvm9gNO3tDYJGlDVNXzp1m19xR1C3jFNPs5Hjh+ivLzgUfPJkZJi8uczJpMsgvwWLrvxpmrGUaSJEmL2qwv1k/yAOCTwN9W1W2DXxQ91zOMNspMogXA9oy2OW9Pz7OIRmYmkyQtQrNKxJLcly4J+1hVnd6K52qG0b1slJlEC8D4lkfbnhE25+3peXbbyMxkkqRFaDazJgMcB1xeVe8YWDUnM4w2NC5JkqSFYjY9Yk8C/gy4JMlFrez1zO0MI0ne/1SSFq3ZzJr8KjDdf4g5mWEkSZK0mHmvSUmSpJ6YiEmSJPXEREySJKknJmKSJEk9MRGTJEnqiYmYJElST0zEJEmSemIiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk9MRGTJEnqiYmYJElST0zEJEmSemIiJkmS1BMTMUmSpJ6YiEmSJPXEREySJKknJmKSJEk9WdJ3AJLm0MczfN0X1PzFIUkaij1ikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPTERkyRJ6omJmCRJUk9MxCRJknpiIiZJktQTEzFJkqSemIhJkiT1xERMkiSpJyZikiRJPVnSdwCSevLxDFdvy6OBsfmMRJI2WfaISZIk9cRETJIkqScmYpIkST0xEZMkSerJyCRiSfZLckWSlUmO6DseSZoPnuskDRqJWZNJNgPeBzwNWAV8M8mKqrqs38gkAcPPsAR4Qc1fHAuc5zpJk41Kj9iewMqquqqqfgGcAhzQc0ySNNc810m6h1FJxHYCrhlYXtXKJGkx8Vwn6R5GYmhyWEkOBw5vi2uTXDHkpjsAP5mfqPrwGtsz0jbx9rxwBsOY8LCZRrMp2Cjnupm9T/Nlof2tGO/8WmjxAn80k5inPN+NSiJ2LbDzwPKyVnYPVXUscOxMd57k/KpavuHhjRbbM9psj9bBc90A451fxjv/5iLmURma/Cawe5Jdk2wOHASs6DkmSZprnusk3cNI9IhV1V1J/go4E9gMOL6qLu05LEmaU57rJE02EokYQFWdAZwxT7ufcRf/iLM9o832aFqe6+7BeOeX8c6/WcecKr/zR5IkqQ+jco2YJEnSJmdRJ2IL/VYiSXZOck6Sy5JcmuSVrXz7JGclubL93K7vWGciyWZJLkzy2ba8a5Lz2vv0iXYR84KQZNskpyX5bpLLkzxxIb8/Sf6u/a59J8nJSbZcyO/PYrW+c1uSLdp7tbK9d7v0EOZgPOuL91XtPHdxkrOT9Pq1JsP+70jyJ0kqSa8z/YaJN8nzBv6XfHxjxzgplvX9Pvy39r/vwvY7sX8fcQ7Ec3ySG5N8Z5r1SfLu1p6LkzxuRgeoqkX5oLsQ9vvAw4HNgW8De/Qd1wzbsCPwuPb8gcD3gD2AfwGOaOVHAG/rO9YZtutVwMeBz7blU4GD2vN/A17Wd4wzaMuJwF+055sD2y7U94fui0WvBu438L4cupDfn8X4GObcBrwc+Lf2/CDgEyMe7x8BW7XnLxv1eFu9BwJfAc4Flo9yvMDuwIXAdm35ISMe77ET55n2P+8HfcXbYvgD4HHAd6ZZvz/weSDAXsB5M9n/Yu4RW/C3Eqmq66rqW+357cDldP8sD6BLAGg/D+wlwA2QZBnwDODDbTnAU4DTWpUF054k29D9gR4HUFW/qKpbWMDvD90EnvslWQJsBVzHAn1/FrFhzm2Dv4OnAXu3v7U+rDfeqjqnqn7WFs+l+361vgz7v+PNwNuAOzZmcFMYJt6XAO+rqjUAVXXjRo5x0DDxFrB1e74N8OONGN+9VNVXgNXrqHIAcFJ1zgW2TbLjsPtfzInYorqVSBtaeCxwHrC0qq5rq64HlvYV1wZ4J/D3wK/b8oOAW6rqrra8kN6nXYGbgH9vXegfTnJ/Fuj7U1XXAkcDP6JLwG4FLmDhvj+L1TDntt/Uae/drXR/a32Y6bn4MLrehb6sN9429LRzVX1uYwY2jWFe30cAj0jytSTnJtlvo0V3b8PE+0bgRUlW0c0w/uuNE9oGm1W+sZgTsUUjyQOATwJ/W1W3Da6rrl90QUx9TfJM4MaquqDvWObIErru6g9U1WOBn9INRf7GAnt/tqP7ZLcr8FDg/kCfJ2xtYpK8CFgO/GvfsUwnyX2AdwCv7juWGVhCNzw5Bjwf+FCSbfsMaD2eD5xQVcvohv0+0l73RWnRNowhbyUy6pLcly4J+1hVnd6Kb5jo9mw/++xmnoknAc9K8gO67uinAO+i68ad+E67hfQ+rQJWVdV5bfk0usRsob4/TwWurqqbquqXwOl079lCfX8Wq2HObb+p0967bYCbN0p09zbUuTjJU4F/AJ5VVXdupNimsr54Hwg8Ghhv57K9gBU9XrA/zOu7ClhRVb+sqqvprjfefSPFN9kw8R5Gd20qVfVfwJZ096EcVbPKNxZzIrbgbyXSruk4Dri8qt4xsGoFcEh7fgjwmY0d24aoqtdV1bKq2oXu/fhyVb0QOAd4Tqu2kNpzPXBNkke2or2By1ig7w/dkOReSbZqv3sT7VmQ788iNsy5bfB38Dl0f2t99cyuN94kjwU+SJeE9f3BZZ3xVtWtVbVDVe3SzmXn0sV9fj/hDvX78Gm63jCS7EA3VHnVRoxx0DDx/oju/EOS36FLxG7aqFHOzArg4DZ7ci/g1oHLU9avz5kI8/2g69L8Ht0MjX/oO54NiP/JdMNaFwMXtcf+dNd6nA1cCXwJ2L7vWDegbWPcPWvy4cA3gJXAfwBb9B3fDNrxGOD89h59GthuIb8/wD8C3wW+A3wE2GIhvz+L9THVuQ14E11CAN0/rv9o79k3gIePeLxfAm4YOM+tGOV4J9Udp8dZk0O+vqEbTr0MuIQ2C3qE490D+BrdjMqLgH16jvdkuutmf0nXu3gY8FLgpQOv7/taey6Z6e+D36wvSZLUk8U8NClJkjTSTMQkSZJ6YiImSZLUExMxSZKknpiISZIk9cRETJIkqScmYpIkST0xEZMkSerJ/w8bpppAT/V98wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot test data histograms\n",
    "test_df_reduced.hist(bins=20, figsize=(10,5), color='orange')\n",
    "plt.suptitle(\"Test Data Histograms\", fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7e0078",
   "metadata": {
    "id": "UUMdp0fk_gPB"
   },
   "source": [
    "The above figures depict that the majority of the `Battery_Status` target variable values are 0 while the rest are 1's. Moreover, the input feature `VehicleSpeed_km_h` comprise values that follow a normal (Gaussian) distribution. Therefore, a suitable scaling method in our case would be standardisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ffe1164",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1635883604985,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "R_63z5KA7Elk",
    "outputId": "649e979c-5ff7-4dec-e4db-6b4315c55729"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data zeroes:ones ratio: 2.7823184515399833\n",
      "\n",
      "Test data zeroes:ones ratio: 2.885824991927672\n"
     ]
    }
   ],
   "source": [
    "# Print the 0's to 1's ratio of the training data\n",
    "all_zeroes_train = train_df[train_df['Battery_Status']==0]['Battery_Status'].count()\n",
    "all_ones_train = train_df[train_df['Battery_Status']==1]['Battery_Status'].count()\n",
    "print(f'Train data zeroes:ones ratio: {(all_zeroes_train/all_ones_train)}\\n')\n",
    "\n",
    "# Print the 0's to 1's ratio of the test data\n",
    "all_zeroes_test = test_df[test_df['Battery_Status']==0]['Battery_Status'].count()\n",
    "all_ones_test = test_df[test_df['Battery_Status']==1]['Battery_Status'].count()\n",
    "print(f'Test data zeroes:ones ratio: {(all_zeroes_test/all_ones_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8083f6be",
   "metadata": {
    "id": "Eqx5zt8B8Tdp"
   },
   "source": [
    "Particularly, we have $\\approx 2.7823$ and $\\approx 2.8858$ or almost 3 times more 0's than 1's in the train and test sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de08a08",
   "metadata": {
    "id": "8c3vUHTbBiaf"
   },
   "source": [
    "#### Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e94604b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1635883606085,
     "user": {
      "displayName": "Casp3r",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s64",
      "userId": "17722606493291528264"
     },
     "user_tz": 0
    },
    "id": "3ebjSua3zEwP",
    "outputId": "f85b9dea-a0d7-412a-8ccb-859ed6c285b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 107085 entries, 0 to 107084\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   VehicleSpeed_km_h_  107085 non-null  float64\n",
      " 1   Battery_Status      107085 non-null  int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 1.6 MB\n",
      "\n",
      "--------------------------------------------------\n",
      "Test Data\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60172 entries, 0 to 60171\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   VehicleSpeed_km_h_  60172 non-null  float64\n",
      " 1   Battery_Status      60172 non-null  int64  \n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 940.3 KB\n"
     ]
    }
   ],
   "source": [
    "# Print the both dataset data types of each feature\n",
    "# together with the memory usage of the data\n",
    "print('Train Data\\n')\n",
    "train_df_reduced.info()\n",
    "print('\\n' + '-'*50 + '\\nTest Data\\n')\n",
    "test_df_reduced.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e02514e",
   "metadata": {
    "id": "xlw5KqNQzFSH"
   },
   "source": [
    "Above we can see that the train and test datasets contain 2 diferent data types `int64` and `float64`. Using 64-bit data consumes great deal of memory and in our case the usage of such data type is inefficient since we are not looking for such a high level of result precision. Hence, we can convert the data type of the data frames to to 32-bit (using `int32` and `float32`) to save some memory and boost the algorithm speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d25e094e",
   "metadata": {
    "id": "lISiSASdzkBe"
   },
   "outputs": [],
   "source": [
    "# Convert both dataset values to 32-bit to save memory usage and boost runtime\n",
    "train_df_32 = train_df_reduced.astype({\"VehicleSpeed_km_h_\": 'float32', \\\n",
    "                               \"Battery_Status\": 'int32'})\n",
    "test_df_32 = test_df_reduced.astype({\"VehicleSpeed_km_h_\": 'float32', \\\n",
    "                             \"Battery_Status\": 'int32'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022cbc5e",
   "metadata": {
    "id": "UYtUX2xnDIVN"
   },
   "source": [
    "#### Separating Features and Labels (Targets)\n",
    "\n",
    "For this we are going to make use of the `DataFrame.iloc[rows, columns]` method offered by the pandas library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb94743a",
   "metadata": {
    "id": "dSaOLdufDUHK"
   },
   "outputs": [],
   "source": [
    "# Divide the single feature from the target variable\n",
    "X_train, y_train = train_df_32.iloc[:,:-1], train_df_32.iloc[:,-1]\n",
    "X_test, y_test = test_df_32.iloc[:,:-1], test_df_32.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a02c188",
   "metadata": {
    "id": "XUZ1_wjRLn7r"
   },
   "source": [
    "#### Feature Scaling\n",
    "\n",
    "In general, unscaled data can cause a network's learning and convergence to be slowed down and in some cases even prevent it from learning the problem sufficiently.\n",
    "\n",
    "We employ standardisation for feature scaling since is not bounded to a certain range making it more robust to outliers. Thus, it is often prefered over the min-max normalisation. \n",
    "\n",
    "\n",
    "Also, this technique centers the data around the mean (becomes 0 of the new distribution) with a standard deviation of 1. It is useful for the optimization algorithms, such as gradient descent, that are used within machine-learning algorithms that weight inputs (e.g., regression and neural networks)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1e841ec",
   "metadata": {
    "id": "xIhzYTZWPkvt"
   },
   "outputs": [],
   "source": [
    "# Import the StandardScaler class\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScaler instance used in standardising our data\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit only to the train data to avoid data leakage from the test set.\n",
    "# Then we transform both the train and test sets.\n",
    "X_train_scaled = sc.fit_transform(X_train)\n",
    "X_test_scaled = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-vancouver",
   "metadata": {
    "id": "refined-vancouver"
   },
   "source": [
    "### Input Data Reshaping and Coverting Labels\n",
    "\n",
    "Below, we define the input shape or the data format so that it is handled properly by our Recurrent Neural Network (`RNN`) models. We proceed as follows:\n",
    "\n",
    "1. The input to every RNN layer must be 3D (samples $\\times$ time steps $\\times$ features). In other words, when fitting the model and making predictions, the input layer expects a 3D array of data, even if a specific dimension contains a single value, e.g., one sample. \n",
    "\n",
    "    - `RNNs` assume that there are one or more samples at the input layer. \n",
    "    \n",
    "    - Subsequently, `RNNs` demand the specification of the number of time steps and features which can be achieved via the `input_shape` argument of the layer. This argument takes the 2-tuple (time steps $\\times$ features). We omit the specifying the number of samples since this is determined by the batch size during model fitting.\n",
    "    - In our case, the `input_shape=(1,1)` because we want to feed 1 point of observation in the samples considering 1 feature at a time (`VehicleSpeed_km_h_`) into the `RNNs`.\n",
    "\n",
    "\n",
    "2. Next, we reshape our input training and test data (the feature vectors) using the already defined input shape. This way we ensure that it is fed in the correct format into the `RNN`. For the purpose, we adopt the Pandas `reshape()` function.\n",
    "\n",
    "\n",
    "3. Finally, we convert the training and test labels to binary matrix representations. That is, the 0's (discharging) and 1's (charging) classes are now converted to the `[1 0]` and `[0 1]` binary matrices respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61714780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New input data shapes: ((107085, 2), (60172, 2))\n",
      "Default labels: 0, 1\n",
      "Binary matrix representations: [1. 0.], [0. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Define the input shape (batch_size, timesteps, data_dim)\n",
    "# Sample - a batch is comprised of one or more samples (sequences).\n",
    "# Time Step - a point of observation in the samples.\n",
    "# Feature - an observation at a time step.\n",
    "INPUT_SHAPE = 1, 1 \n",
    "\n",
    "# Reshape the train and test input data\n",
    "X_train_rs = X_train_scaled.reshape(-1, *INPUT_SHAPE)\n",
    "X_test_rs = X_test_scaled.reshape(-1, *INPUT_SHAPE)\n",
    "\n",
    "# Specify the number of classes as a constant\n",
    "# which is reused later\n",
    "NUM_CLASSES = 2\n",
    "\n",
    "# Convert our class vector (integers) to binary class matrix.\n",
    "y_train_bm = tf.keras.utils.to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_test_bm = tf.keras.utils.to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "# Print the changes\n",
    "print(f'New input data shapes: {y_train_bm.shape, y_test_bm.shape}')\n",
    "print(f'Default labels: {y_train[71]}, {y_train[72]}')\n",
    "print(f'Binary matrix representations: {y_train_bm[71]}, {y_train_bm[72]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ec28cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Tensorflow addons module which is \n",
    "# used for employing additional binary classification \n",
    "# metrics such as F1 score, precision, recall, etc\n",
    "# !pip install tensorflow-addons[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "349c4787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Keras layer used for building our models\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Dense, Flatten,\\\n",
    "Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc17ddc8",
   "metadata": {},
   "source": [
    "USE RELU FOR HIDDEN AND SIGMOID ON OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "opposed-discovery",
   "metadata": {
    "id": "opposed-discovery"
   },
   "source": [
    "### Developing our Baseline RNN Models\n",
    "\n",
    "In this section we go over our simple `RNN` and `LSTM` baseline models. These will serve as the foundational models for further tuning and improvement. By adopting them, we set a minimum reference model performances for later comparison. Both models are inspirated by <a href=\"https://www.tensorflow.org/guide/keras/rnn\">Tensorflow</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b057ef3d",
   "metadata": {},
   "source": [
    "#### The Simple RNN Architecture\n",
    "\n",
    "In the field of AI, Recurrent Neural Networks (`RNNs`) are used for modelling data sequences, such as time series or natural language. An `RNN` layer iterates over the time steps of a sequence using a loop, while maintaining an internal state that provides information about the time steps it has observed so far.\n",
    "\n",
    "- Disadvantage &ndash; `RNNs` are prone to the so called vanishing gradient problem. This is caused by the large number of steps being processed. That is, if the gradient gets smaller and smaller at each step of the backpropagation, this causes their exponential shrink and eventually vanish without updating some of the weights. Thus, that would mean that the model would stop learning.\n",
    "\n",
    "\n",
    "We adopt the Keras `Sequential` API when constructing our simple `RNN`. The `RNN` structure is defined below:\n",
    "\n",
    "\n",
    "- `SimpleRNN(128)` &ndash; we define the single `RNN` layer with 128 units\n",
    "\n",
    "\n",
    "- `BatchNormalization()` &ndash; normalisation layer that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
    "\n",
    "\n",
    "- `Dropout(0.25)` &ndash; a dropout layer with 25% drop rate to decrease overfitting\n",
    "\n",
    "\n",
    "- `Dense(10)` &ndash; a fully-connected layer with 10 outputs (units)\n",
    "\n",
    "\n",
    "- `BatchNormalization()` &ndash; normalisation layer\n",
    "\n",
    "\n",
    "- `Dropout(0.25)` &ndash; a dropout layer with 25% drop rate to decrease overfitting\n",
    "\n",
    "\n",
    "- `Dense(NUM_CLASSES)` &ndash; final fully-connected layer with `NUM_CLASSES=2` outputs since we are dealing with binary classification problem\n",
    "\n",
    "<center>\n",
    "    <br>\n",
    "    <figure>\n",
    "        <img src=\"https://drive.google.com/uc?id=1W9nqJYXLLkY7_yGfQivz1drImvIQlOzX\" width=\"350\">\n",
    "        <br>\n",
    "        <figcaption style=\"text-align:center\"><b>Fig. 1.</b> Baseline simple RNN architecture.</figcaption>\n",
    "    </figure>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "\n",
    "    Considering `CNNs`, it is recommended to begin with smaller filter sizes for better local information capturing. That is, to enable the model to detect low-level features used in forming complex shapes later on. As we go deeper we gradually increase the filter size which reduces the resulting feature space to reflect higher-level information. Moreover, deepening and narrowing the feature space allows the input to be fed into a `Dense` layer. \n",
    "\n",
    "- Activation function &ndash; We adopt the `ReLU` activation function to achieve nonlinearity. It is preferred over `tanh` and `sigmoid` activation functions due to its trivial implementation (requires only a `max()` function), representational sparsity (outputs a true zero value), linear function characteristics (easier to optimise) and enables proper deep neural network training.\n",
    "\n",
    "\n",
    "- Batch normalisation &ndash; intermediate layers are capable of amending the already normalised input before it gets to the deeper layers of the neural network. This might cause an internal co-variate shift that can influence the model learning. A solution to this problem is adding the `BatchNormalization` layer which standardises (centers the mean and scales the variance) the input passed to the inner layers. This layer is generally placed after the activation function output but before the `Dropout` layer (if any). The <a href=\"https://arxiv.org/abs/1502.03167\">original paper</a> that introduces the technique suggests otherwise. Nevertheless, there are reported <a href=\"https://github.com/ducha-aiki/caffenet-benchmark/blob/master/batchnorm.md\">practical experiments</a> suggesting that the application of the `BatchNormalization` layer after the activation function yields better results. This seems rather reasonable since feeding the batch-normalised output to an activation layer would lead to its alteration and would nullify the conducted normalisation. Hence, we put the `BatchNormalization` layer after the activation function in our `SimpleRNN` and `LSTM` networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4d36b2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_rnn_model():\n",
    "    \"\"\"Construct and return the simple RNN model architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(SimpleRNN(128, input_shape=(1,1), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd97aec",
   "metadata": {},
   "source": [
    "#### The LSTM Architecture\n",
    "\n",
    "    The `MLP` architecture we develop vertically stacks  2 LSTM layers together \n",
    "    SAY ABOUT ADVANTAGE OVER RNN\n",
    "\n",
    "    RNN width is defined by (1) # of input channels; (2) # of cell's filters (output channels/units). As with CNN, each RNN filter is an independent feature extractor: more is suited for higher-complexity information, including but not limited to: dimensionality, modality, noise, frequency.\n",
    "    RNN depth is defined by (1) # of stacked layers; (2) # of timesteps. Specifics will vary by architecture, but from information standpoint, unlike CNNs, RNNs are dense: every timestep influences the ultimate output of a layer, hence the ultimate output of the next layer - so it again isn't as simple as \"more nonlinearity\"; stacked RNNs exploit both spatial and temporal information.\n",
    "\n",
    "\n",
    "\n",
    "    In case of a simple feedforward net we stack layers to create a hierarchical feature representation of the input data to then use for some machine learning task. The same applies for stacked LSTM's. If the input is already the result from an LSTM layer (or a feedforward layer) then the current LSTM can create a more complex feature representation of the current input. \n",
    "\n",
    "    As discussed before, the Keras Sequential API is used for creating the model. \n",
    "\n",
    "    Every LSTM layer should be accompanied by a Dropout layer. This layer will help to prevent overfitting by ignoring randomly selected neurons during training, and hence reduces the sensitivity to the specific weights of individual neurons. 20% is often used as a good compromise between retaining model accuracy and preventing overfitting.\n",
    "\n",
    "    In general, width extracts more features, whereas depth extracts richer features - but if there aren't many features to extract from given data, width should be lessened - and the \"simpler\" the data/problem, the less layers are suitable.\n",
    "\n",
    "\n",
    "- `LSTM(128)` &ndash; the first `LSTM` layer with 128 units\n",
    "\n",
    "\n",
    "- `BatchNormalization()` &ndash; normalisation layer that maintains the mean output close to 0 and the output standard deviation close to 1.\n",
    "\n",
    "\n",
    "- `Dropout(0.25)` &ndash; a dropout layer with 25% drop rate to decrease overfitting\n",
    "\n",
    "\n",
    "- `LSTM(64)` &ndash; a second `LSTM` layer with 64 units\n",
    "\n",
    "\n",
    "- `BatchNormalization()` &ndash; normalisation layer\n",
    "\n",
    "\n",
    "- `Dropout(0.25)` &ndash; a dropout layer with 25% drop rate to decrease overfitting\n",
    "\n",
    "\n",
    "- `Dense(10)` &ndash; a fully-connected layer with 10 outputs (units)\n",
    "\n",
    "\n",
    "- `BatchNormalization()` &ndash; normalisation layer\n",
    "\n",
    "\n",
    "- `Dropout(0.25)` &ndash; a dropout layer with 25% drop rate to decrease overfitting\n",
    "\n",
    "\n",
    "- `Dense(NUM_CLASSES)` &ndash; final fully-connected layer with `NUM_CLASSES=2` outputs since we are dealing with binary classification problem\n",
    "\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "<figure>\n",
    "<img src=\"https://drive.google.com/uc?id=1JyzQ-4IsQ5mT6C-lZwXCYo84OGry5jbp\" width=\"350\">\n",
    "<br>\n",
    "<figcaption style=\"text-align:center\"><b>Fig. 2.</b> Baseline simple RNN architecture.</figcaption>\n",
    "</figure>\n",
    "<br>\n",
    "</center>\n",
    "\n",
    "    The final `Dense` layer has 2 output neuron and activates linearly (no function specified). Using the linear function allows us to generate a real-valued or numeric prediction, which is exactly what we need. That is, we do not want to change in any way our prediction output which non-linear activation functions in the last layer might cause.\n",
    "\n",
    "     we consider greater number of features before converging to the actual prediction.\n",
    "\n",
    "    We use `ReLU` based activation because it is one of the standard activation functions used nowadays (as detailed above).\n",
    "\n",
    "    Next, we define the MLP in code:\n",
    "\n",
    "RELU Found much success in computer vision applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45a91c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_model():\n",
    "    \"\"\"Construct and return the LSTM model architecture\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(128, input_shape=(1,1), activation='relu', return_sequences=True)) # return_sequence=True\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(LSTM(64, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Dense(NUM_CLASSES, activation='sigmoid'))\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb9182c",
   "metadata": {},
   "source": [
    "### Defining the Baseline Model Configuration\n",
    "\n",
    "- **Batch size** &ndash; The batch size is a hyperparameter used for spicifying the amount of samples that will be sent across the network. As a kickoff, we use a batch size of 32 samples which is stated to be a good default value in the <a href=\"https://arxiv.org/abs/1206.5533\">following paper</a>. In general, smaller batch sizes are mainly used because they offer regularisation and improved generalisation.\n",
    "\n",
    "\n",
    "- **Epochs** &ndash; this is the number of passes of the whole training dataset the algorithm is expected to complete. We use 10 epochs to quickly evaluate our baseline models. We will adjust this hyperparameter later on when we conduct the model hyperparameter optimisation procedure.\n",
    "\n",
    "\n",
    "- **Validation split** &ndash; we adopt 25% of the training data, or 20% of the whole dataset, for validation training of our baseline models.\n",
    "\n",
    "\n",
    "- **Optimiser** &ndash; we pick the `Adam` algorithm since it is a popular deep learning method that quickly produces good results. This optimiser combines the advantages of the AdaGrad and RMSProp algorithms into a technique that can tackle sparse gradients on noisy tasks. We use the default `learning_rate=0.001` value of the `Adam` algorithm for our baseline model evaluations which is to be tuned at a later point.\n",
    "\n",
    "\n",
    "- **Loss function** &ndash; we use the Mean Squared Error (`MSE`) loss function which is the default for regression problems. Furthermore, we choose the `RMSE` metric to report the performance of our models. \n",
    "\n",
    "\n",
    "Finally, we wish to see as much output as possible, thus configure the training process to be verbose.\n",
    "Cross-entropy is the default loss function to use for binary classification problems.\n",
    "\n",
    "It is intended for use with binary classification where the target values are in the set {0, 1}.\n",
    "\n",
    "Cross-entropy will calculate a score that summarizes the average difference between the actual and predicted probability distributions for predicting class 1. The score is minimized and a perfect cross-entropy value is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb1244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "LOSS = BinaryCrossentropy()\n",
    "OPTIMISER = Adam()\n",
    "METRICS = ['accuracy', F1Score(num_classes=NO_CLASSES, average = 'macro')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f7dfceb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "simple_rnn_24 (SimpleRNN)    (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "dropout_44 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "dropout_45 (Dropout)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 18,504\n",
      "Trainable params: 18,228\n",
      "Non-trainable params: 276\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = simple_rnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e08037a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 293/2510 [==>...........................] - ETA: 40s - loss: 0.8208 - accuracy: 0.5234 - f1_score: 0.4803"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10472/2401798641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'f1_score'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m model.fit(X_train_rs, y_train_new, epochs=10, \n\u001b[0m\u001b[0;32m     16\u001b[0m                         \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m.25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1191\u001b[0m                 _r=1):\n\u001b[0;32m   1192\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1193\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    884\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 885\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    886\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    915\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3037\u001b[0m       (graph_function,\n\u001b[0;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 3039\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   3041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1962\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1963\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    589\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 591\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.metrics import F1Score\n",
    "from tensorflow.keras.metrics import Precision, Recall, AUC\n",
    "from tensorflow.keras.losses import BinaryCrossentropy      \n",
    "\n",
    "# https://www.tensorflow.org/text/tutorials/text_classification_rnn\n",
    "\n",
    "# from_logits=True when output values are not [0, 1]\n",
    "model.compile(loss=LOSS,\n",
    "              optimizer=OPTIMISER,\n",
    "              metrics=METRICS)\n",
    "\n",
    "es_callback = tf.keras.callbacks.\\\n",
    "    EarlyStopping(monitor='f1_score', patience=3)\n",
    "\n",
    "model.fit(X_train_rs, y_train_new, epochs=10, \n",
    "                        validation_split=.25,\n",
    "                        batch_size=32, verbose=1,\n",
    "                        callbacks=[es_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "dbbac1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1db3f7cef10>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(range(20),y_train[:20], c='g')\n",
    "plt.scatter(range(20),y_test[:20], c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4e879bd6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pyplot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10472/3219398863.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# plot loss during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m211\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpyplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pyplot' is not defined"
     ]
    }
   ],
   "source": [
    "# plot loss during training\n",
    "pyplot.subplot(211)\n",
    "pyplot.title('Loss')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "# plot accuracy during training\n",
    "pyplot.subplot(212)\n",
    "pyplot.title('Accuracy')\n",
    "pyplot.plot(history.history['accuracy'], label='train')\n",
    "pyplot.plot(history.history['val_accuracy'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d16c21",
   "metadata": {},
   "source": [
    "https://www.pluralsight.com/guides/deep-learning-model-perform-binary-classification\n",
    "\n",
    "- The above code compiles the network. It uses Adam, a momentum-based optimizer. The loss function used is binary_crossentropy. \n",
    "\n",
    "\n",
    "- For binary classification problems that give output in the form of probability, binary_crossentropy is usually the optimizer of choice. \n",
    "\n",
    "\n",
    "- mean_squared_error may also be used instead of binary_crossentropy as well. Metrics used is accuracy. \n",
    "\n",
    "\n",
    "- The model is trained for 50 epochs with a batch size of 1. Finally, the trained model was evaluated for the test set to check the accuracy.\n",
    "\n",
    "\n",
    "If your problem is a binary classification problem, then the output will be class values 0 and 1. This is best modeled with a sigmoid activation function on the output layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f708fc",
   "metadata": {},
   "source": [
    "FINAL\n",
    "\n",
    "Did not consider Keras Tuner + Cross-validation due to time constraints but left for future work. It would be painfully slow to train a single RNN model.\n",
    "\n",
    "try different scaling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
